import os
import re
import json
import logging
import time
import uuid
import streamlit as st
import google.generativeai as genai

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 0. Î°úÍ∑∏ Î∞è Í≤ΩÍ≥† ÏñµÏ†ú
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.getLogger("google.auth").setLevel(logging.ERROR)
os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GLOG_minloglevel"] = "3"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 1. Gemini API ÏÑ§Ï†ï
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
else:
    st.warning("‚ö†Ô∏è GOOGLE_API_KEYÍ∞Ä ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏßÄ ÏïäÏäµÎãàÎã§. Streamlit secretsÏóê Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.")

DEFAULT_MODEL = "gemini-2.5-flash"
DATA_EVIDENCE_GUIDE = (
    "\n\nÏ∂îÍ∞Ä ÏßÄÏπ®:\n"
    "- Í∞Å Ï†úÏïàÏóêÎäî Îç∞Ïù¥ÌÑ∞ Í∑ºÍ±∞(Ìëú/ÏßÄÌëú/Í∑úÏπô Îì±)Î•º Ìï®Íªò ÌëúÍ∏∞ÌïòÏÑ∏Ïöî.\n"
    "- Í∞ÄÎä•Ìïú Í≤ΩÏö∞ Í∞ÑÎã®Ìïú ÌëúÎÇò ÏßÄÌëú ÏàòÏπòÎ•º ÌôúÏö©Ìï¥ Í∑ºÍ±∞Î•º Î™ÖÌôïÌûà Î≥¥Ïó¨Ï£ºÏÑ∏Ïöî."
)

STRUCTURED_RESPONSE_GUIDE = (
    "\n\nÏùëÎãµ ÌòïÏãù ÏßÄÏπ®(Ï§ëÏöî):\n"
    "1. Î∞òÎìúÏãú Î∞±Ìã±Ïù¥ÎÇò Ï£ºÏÑù ÏóÜÏù¥ ÏàúÏàò JSONÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî.\n"
    "2. JSONÏùÄ ÏïÑÎûò Ïä§ÌÇ§ÎßàÎ•º Îî∞Î•¥ÏÑ∏Ïöî.\n"
    "{\n"
    '  \"objective\": \"ÏµúÏö∞ÏÑ† ÎßàÏºÄÌåÖ Î™©ÌëúÎ•º 1Î¨∏Ïû•ÏúºÎ°ú ÏöîÏïΩ\",\n'
    '  \"phase_titles\": [\"Phase 1: ‚Ä¶\", \"Phase 2: ‚Ä¶\", \"Phase 3: ‚Ä¶\"],\n'
    '  \"channel_summary\": [\n'
    '    {\n'
    '      \"channel\": \"Ï±ÑÎÑêÎ™Ö\",\n'
    '      \"phase_title\": \"Ïó∞Í≤∞Îêú Phase Ï†úÎ™©\",\n'
    '      \"reason\": \"Ï∂îÏ≤ú Ïù¥Ïú†ÏôÄ Í∏∞ÎåÄ Ìö®Í≥º\",\n'
    '      \"data_evidence\": \"Í¥ÄÎ†® ÏàòÏπò/Í∑úÏπô Îì± Îç∞Ïù¥ÌÑ∞ Í∑ºÍ±∞\"\n'
    "    }\n"
    "  ],\n"
    '  \"phases\": [\n'
    "    {\n"
    '      \"title\": \"Phase 1: ‚Ä¶\",\n'
    '      \"goal\": \"Íµ¨Ï≤¥Ï†ÅÏù∏ Î™©Ìëú\",\n'
    '      \"focus_channels\": [\"ÌïµÏã¨ Ï±ÑÎÑê 1\", \"ÌïµÏã¨ Ï±ÑÎÑê 2\"],\n'
    '      \"actions\": [\n'
    "        {\n"
    '          \"task\": \"Ï≤¥ÌÅ¨Î∞ïÏä§Ïóê Îì§Ïñ¥Í∞à Ïã§Ìñâ Ìï≠Î™©\",\n'
    '          \"owner\": \"Îã¥Îãπ Ïó≠Ìï†(Ïòà: Ï†êÏ£º, Ïä§ÌÉúÌîÑ)\",\n'
    '          \"supporting_data\": \"ÏÑ†ÌÉù) Í¥ÄÎ†® Îç∞Ïù¥ÌÑ∞ Í∑ºÍ±∞\"\n'
    "        }\n"
    "      ],\n"
    '      \"metrics\": [\"ÏÑ±Í≥º KPI\"],\n'
    '      \"next_phase_criteria\": [\"Îã§Ïùå PhaseÎ°ú ÎÑòÏñ¥Í∞ÄÍ∏∞ ÏúÑÌïú Ï†ïÎüâ/Ï†ïÏÑ± Í∏∞Ï§Ä\"],\n'
    '      \"data_evidence\": [\"Phase Ï†ÑÎûµÏùÑ Îí∑Î∞õÏπ®ÌïòÎäî Í∑ºÍ±∞\"]\n'
    "    }\n"
    "  ],\n"
    '  \"risks\": [\"Ï£ºÏöî Î¶¨Ïä§ÌÅ¨ÏôÄ ÎåÄÏùë ÏöîÏïΩ\"],\n'
    '  \"monitoring_cadence\": \"Î™®ÎãàÌÑ∞ÎßÅ Ï£ºÍ∏∞ÏôÄ Ï±ÖÏûÑÏûê\"\n'
    "}\n"
    "3. PhaseÎäî ÏãúÍ∞Ñ ÏàúÏÑúÎ•º ÏßÄÌÇ§Í≥† Phase 1Ïùò action Ìï≠Î™©ÏùÄ ÏµúÏÜå 3Í∞úÎ•º Ìè¨Ìï®ÌïòÏÑ∏Ïöî.\n"
    "4. Î™®Îì† reason, supporting_data, data_evidenceÏóêÎäî Ï†ïÎüâ ÏàòÏπòÎÇò Í∑úÏπôÏ†Å Í∑ºÍ±∞Î•º Î™ÖÏãúÌïòÏÑ∏Ïöî."
)


def ensure_data_evidence(prompt: str) -> str:
    """ÌîÑÎ°¨ÌîÑÌä∏Ïóê Îç∞Ïù¥ÌÑ∞ Í∑ºÍ±∞ ÏßÄÏπ®Ïù¥ ÏóÜÏúºÎ©¥ Ï∂îÍ∞Ä."""
    updated = prompt.rstrip()
    if "Îç∞Ïù¥ÌÑ∞ Í∑ºÍ±∞" not in updated:
        updated += DATA_EVIDENCE_GUIDE
    if '"phase_titles"' not in updated and "ÏùëÎãµ ÌòïÏãù ÏßÄÏπ®(Ï§ëÏöî)" not in updated:
        updated += STRUCTURED_RESPONSE_GUIDE
    return updated


def extract_executive_summary(markdown_text: str, max_points: int = 4):
    """ÏÉùÏÑ±Îêú Ï†ÑÎûµ Î≥∏Î¨∏ÏóêÏÑú ÏöîÏïΩ ÏÑπÏÖòÏùò ÌïµÏã¨ Î∂àÎ¶øÏùÑ Ï∂îÏ∂ú."""
    lines = markdown_text.splitlines()
    summary_lines = []

    def clean_bullet(line):
        stripped = line.strip()
        if not stripped:
            return None
        bullet_match = re.match(r"^[-\*\u2022]\s*(.+)", stripped)
        if bullet_match:
            return bullet_match.group(1).strip()
        numbered_match = re.match(r"^\d+[.)]\s*(.+)", stripped)
        if numbered_match:
            return numbered_match.group(1).strip()
        return None

    heading_pattern = re.compile(r"#{1,6}\s*ÏöîÏïΩ")
    start_idx = next(
        (idx for idx, line in enumerate(lines) if heading_pattern.match(line.strip())),
        None,
    )

    if start_idx is not None:
        for line in lines[start_idx + 1 :]:
            stripped = line.strip()
            if stripped.startswith("#"):
                break
            cleaned = clean_bullet(stripped)
            if cleaned:
                summary_lines.append(cleaned)
            if len(summary_lines) >= max_points:
                break

    if not summary_lines:
        for line in lines:
            cleaned = clean_bullet(line)
            if cleaned:
                summary_lines.append(cleaned)
            if len(summary_lines) >= max_points:
                break

    if not summary_lines:
        collapsed = re.sub(r"\s+", " ", markdown_text)
        sentences = re.split(r"(?<=[.!?])\s", collapsed)
        for sentence in sentences:
            cleaned = sentence.strip()
            if cleaned:
                summary_lines.append(cleaned)
            if len(summary_lines) >= max_points:
                break

    return summary_lines


def strip_json_artifacts(text: str) -> str:
    """Ïä§Ìä∏Î¶¨Î∞ç Ï§ë ÏÑûÏùº Ïàò ÏûàÎäî Î∂àÌïÑÏöîÌïú Î¨∏ÏûêÎ•º Ï†úÍ±∞ÌïòÍ≥† ÏàúÏàò JSON Î¨∏ÏûêÏó¥Îßå ÎÇ®Í∏¥Îã§."""
    cleaned = text.strip().replace("‚ñå", "")
    fence_pattern = re.compile(r"^```(?:json)?\s*|\s*```$")
    cleaned = fence_pattern.sub("", cleaned)
    return cleaned.strip()


def parse_strategy_payload(raw_text: str):
    """JSON ÏùëÎãµÏùÑ ÏïàÏ†ÑÌïòÍ≤å ÌååÏã±. Ïã§Ìå® Ïãú None."""
    candidate = strip_json_artifacts(raw_text)
    if not candidate:
        return None
    try:
        return json.loads(candidate)
    except json.JSONDecodeError:
        return None


def render_strategy_payload(payload: dict, container, prefix: str = "latest"):
    """Íµ¨Ï°∞ÌôîÎêú Ï†ÑÎûµ ÏùëÎãµÏùÑ Streamlit Ïª¥Ìè¨ÎÑåÌä∏Î°ú ÏãúÍ∞ÅÌôî."""
    objective = payload.get("objective")
    if objective:
        container.markdown("### üéØ Objective")
        container.markdown(objective)

    phase_titles = payload.get("phase_titles") or []
    channel_summary = payload.get("channel_summary") or []
    if channel_summary:
        container.markdown("### üìä Recommended Channels & Phase Titles")
        summary_lines = []
        for item in channel_summary:
            channel = item.get("channel", "Ï±ÑÎÑê ÎØ∏ÏßÄÏ†ï")
            phase_title = item.get("phase_title", "Phase ÎØ∏ÏßÄÏ†ï")
            reason = item.get("reason", "")
            evidence = item.get("data_evidence", "")
            detail = f"- **{channel}** ‚Üí {phase_title}: {reason}"
            if evidence:
                detail += f" _(Í∑ºÍ±∞: {evidence})_"
            summary_lines.append(detail)
        container.markdown("\n".join(summary_lines))
        if phase_titles:
            container.markdown("**Phase Titles:** " + ", ".join(phase_titles))
    elif phase_titles:
        container.markdown("### üìã Phase Titles")
        container.markdown(", ".join(phase_titles))

    phases = payload.get("phases") or []
    if not phases:
        return

    # Phase 1 Ïö∞ÏÑ† ÌëúÏãú
    phase1 = phases[0]
    phase1_container = container.container()
    phase1_container.markdown(f"### üöÄ {phase1.get('title', 'Phase 1')}")
    goal = phase1.get("goal")
    if goal:
        phase1_container.markdown(f"**Goal:** {goal}")
    focus_channels = phase1.get("focus_channels") or []
    if focus_channels:
        phase1_container.markdown("**Focus Channels:** " + ", ".join(focus_channels))

    actions = phase1.get("actions") or []
    if actions:
        phase1_container.markdown("**Action Checklist:**")
        for idx, action in enumerate(actions):
            label = action.get("task", f"Action {idx + 1}")
            owner = action.get("owner")
            support = action.get("supporting_data")
            help_parts = []
            if owner:
                help_parts.append(f"Îã¥Îãπ: {owner}")
            if support:
                help_parts.append(f"Í∑ºÍ±∞: {support}")
            help_text = " | ".join(help_parts) if help_parts else None
            checkbox_key = f"{prefix}_phase1_action_{idx}"
            phase1_container.checkbox(label, key=checkbox_key, help=help_text)

    metrics = phase1.get("metrics") or []
    if metrics:
        phase1_container.markdown("**Metrics:**")
        phase1_container.markdown("\n".join(f"- {m}" for m in metrics))

    criteria = phase1.get("next_phase_criteria") or []
    if criteria:
        phase1_container.markdown("**Criteria To Advance:**")
        phase1_container.markdown("\n".join(f"- {c}" for c in criteria))

    evidence = phase1.get("data_evidence") or []
    if evidence:
        phase1_container.markdown("**Data Evidence:**")
        phase1_container.markdown("\n".join(f"- {e}" for e in evidence))

    # ÎÇòÎ®∏ÏßÄ PhaseÎäî ExpanderÎ°ú ÌëúÏãú
    for idx, phase in enumerate(phases[1:], start=2):
        title = phase.get("title", f"Phase {idx}")
        expander = container.expander(title, expanded=False)
        goal = phase.get("goal")
        if goal:
            expander.markdown(f"**Goal:** {goal}")
        focus_channels = phase.get("focus_channels") or []
        if focus_channels:
            expander.markdown("**Focus Channels:** " + ", ".join(focus_channels))

        actions = phase.get("actions") or []
        if actions:
            expander.markdown("**Key Actions:**")
            expander.markdown("\n".join(f"- [ ] {act.get('task', 'ÏûëÏóÖ ÎØ∏Ï†ï')}" for act in actions))

        metrics = phase.get("metrics") or []
        if metrics:
            expander.markdown("**Metrics:**")
            expander.markdown("\n".join(f"- {m}" for m in metrics))

        criteria = phase.get("next_phase_criteria") or []
        if criteria:
            expander.markdown("**Criteria To Advance:**")
            expander.markdown("\n".join(f"- {c}" for c in criteria))

        evidence = phase.get("data_evidence") or []
        if evidence:
            expander.markdown("**Data Evidence:**")
            expander.markdown("\n".join(f"- {e}" for e in evidence))

    risks = payload.get("risks") or []
    monitoring_cadence = payload.get("monitoring_cadence")
    if risks or monitoring_cadence:
        container.markdown("### ‚ö†Ô∏è Risks & Monitoring")
        if risks:
            container.markdown("\n".join(f"- {r}" for r in risks))
        if monitoring_cadence:
            container.markdown(f"**Monitoring Cadence:** {monitoring_cadence}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 2. Persona Îç∞Ïù¥ÌÑ∞ Î°úÎìú
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data
def load_personas(path="personas.json"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        st.error("‚ö†Ô∏è personas.json ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. prompt_generator.pyÎ•º Î®ºÏ†Ä Ïã§ÌñâÌïòÏÑ∏Ïöî.")
        return []

personas = load_personas()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 3. ÏóÖÏ¢Ö Î∂ÑÎ•ò
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def classify_hpsn_mct(name: str) -> str:
    nm = name.strip().lower()
    if any(k in nm for k in ["Ïπ¥Ìéò", "Ïª§Ìîº", "ÎîîÏ†ÄÌä∏", "ÎèÑÎÑàÏ∏†", "ÎπôÏàò", "ÏôÄÌîå", "ÎßàÏπ¥Î°±"]):
        return "Ïπ¥Ìéò/ÎîîÏ†ÄÌä∏"
    if any(k in nm for k in ["ÌïúÏãù", "Íµ≠Î∞•", "Î∞±Î∞ò", "Ï∞åÍ∞ú", "Í∞êÏûêÌÉï", "Î∂ÑÏãù", "ÏπòÌÇ®", "ÌïúÏ†ïÏãù", "Ï£Ω"]):
        return "ÌïúÏãù"
    if any(k in nm for k in ["ÏùºÏãù", "Ï¥àÎ∞•", "ÎèàÍ∞ÄÏä§", "ÎùºÎ©ò", "ÎçÆÎ∞•", "ÏÜåÎ∞î", "Ïù¥ÏûêÏπ¥Ïïº"]):
        return "ÏùºÏãù"
    if any(k in nm for k in ["Ï§ëÏãù", "Ïß¨ÎΩï", "ÏßúÏû•", "ÎßàÎùº", "Ìõ†Í∂à", "Îî§ÏÑ¨"]):
        return "Ï§ëÏãù"
    if any(k in nm for k in ["ÏñëÏãù", "Ïä§ÌÖåÏù¥ÌÅ¨", "ÌîºÏûê", "ÌååÏä§ÌÉÄ", "ÌñÑÎ≤ÑÍ±∞", "ÏÉåÎìúÏúÑÏπò", "ÌÜ†Ïä§Ìä∏", "Î≤ÑÍ±∞"]):
        return "ÏñëÏãù/ÏÑ∏Í≥ÑÏöîÎ¶¨"
    if any(k in nm for k in ["Ï£ºÏ†ê", "Ìò∏ÌîÑ", "Îß•Ï£º", "ÏôÄÏù∏Î∞î", "ÏÜåÏ£º", "ÏöîÎ¶¨Ï£ºÏ†ê", "Ïù¥ÏûêÏπ¥Ïïº"]):
        return "Ï£ºÏ†ê/Ï£ºÎ•ò"
    return "Í∏∞ÌÉÄ"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 4. ÌîÑÎûúÏ∞®Ïù¥Ï¶à ÌåêÎ≥Ñ
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BRAND_KEYWORDS = {
    "ÌååÎ¶¨","ÎöúÎ†à","Î∞∞Ïä§","ÎçòÌÇ®","Ìà¨Ïç∏","Ïù¥Îîî","ÎπΩÎã§","Î©îÍ∞Ä","Ïª¥Ìè¨","Ìï†Î¶¨",
    "Ïä§ÌÉÄÎ≤Ö","ÌÉêÏï§","Í≥µÏ∞®","ÏöîÍ±∞","ÏôÄÌîå","ÍµêÏ¥å","ÎÑ§ÎÑ§","Ìò∏Ïãù","ÎëòÎëò","Ï≤òÍ∞ì",
    "ÍµΩÎÑ§","bbq","bhc","ÎßòÏä§","Ï£†Ïä§","Ïã†Ï†Ñ","Î™ÖÎûë","ÎëêÎÅº","ÎïÖÏä§",
    "ÎèÑÎØ∏","ÌååÌåå","Î°ØÎç∞","Î≤ÑÍ±∞ÌÇπ","Ïç®Î∏å","Ïù¥ÏÇ≠","Î™ÖÎ•ú","ÌïòÎÇ®","ÌïúÏã†",
    "Îì±Ï¥å","Î¥âÏ∂î","ÏõêÌï†","Î≥∏Ï£Ω","ÌïúÏ¥å","Î∞±Ï±Ñ","ÌîÑÎû≠","Î∞îÎ•¥","ÌïúÏÜ•","Î≤†Ïä§"
}
AMBIGUOUS_NEGATIVES = {
    "Ïπ¥Ìéò","Ïª§Ìîº","ÏôïÏã≠","ÏÑ±Ïàò","ÌñâÎãπ","Ï¢ÖÎ°ú","Ï†ÑÏ£º","Ï∂òÏ≤ú","ÏôÄÏù∏","ÏπòÌÇ®","ÌîºÏûê",
    "Î∂ÑÏãù","Íµ≠Ïàò","Ï¥àÎ∞•","Í≥±Ï∞Ω","ÎèºÏßÄ","ÌïúÏö∞"
}

def _normalize_name(name: str) -> str:
    n = name.lower()
    n = re.sub(r"[\s\*\-\(\)\[\]{}_/\\.|,!?&^%$#@~`+=:;\"']", "", n)
    return n

def is_franchise(name: str) -> bool:
    n = _normalize_name(name)
    if not n:
        return False
    has_branch_marker = "Ï†ê" in name
    hit = any(k in n for k in BRAND_KEYWORDS)
    if hit:
        if any(bad in n for bad in AMBIGUOUS_NEGATIVES):
            short_hits = [k for k in BRAND_KEYWORDS if k in n and len(k) <= 2]
            if short_hits and not has_branch_marker:
                return False
        return True
    return False


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 5. Gemini Streaming Ìò∏Ï∂ú
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DEFAULT_MODEL = "gemini-2.5-flash"

# https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash
def stream_gemini(
    prompt,
    model=DEFAULT_MODEL,
    temperature=0.6,
    max_tokens=65535,
    output_placeholder=None,
):
    """ÏïàÏ†ïÏ†ÅÏù∏ Ïä§Ìä∏Î¶¨Î∞ç + ÏôÑÎ£åÏÇ¨Ïú† Ï†êÍ≤Ä + ÏπúÏ†àÌïú ÏóêÎü¨"""
    status_placeholder = st.empty()
    status_placeholder.info("Ï†ÑÎûµÏùÑ ÏÉùÏÑ±Ï§ëÏûÖÎãàÎã§... ‚è≥")
    step_interval = 2.0
    step_state = {"idx": 0, "next_time": time.time() + step_interval}

    try:
        gmodel = genai.GenerativeModel(model)
        cfg = {
            "temperature": temperature,
            "max_output_tokens": max_tokens,
            "top_p": 0.9,
            "top_k": 40,
        }

        stream = gmodel.generate_content(prompt, generation_config=cfg, stream=True)

        placeholder = output_placeholder or st.empty()
        placeholder.info("AIÍ∞Ä Ï†ÑÎûµÏùÑ Ï†ïÎ¶¨ÌïòÍ≥† ÏûàÏñ¥Ïöî... üìã")
        full_text = ""

        # 1) Ïä§Ìä∏Î¶¨Î∞ç ÏàòÏßë (chunk.textÍ∞Ä ÏóÜÏùÑ ÏàòÎèÑ ÏûàÏúºÎãà candidatesÎèÑ ÌôïÏù∏)
        for event in stream:
            piece = ""
            if getattr(event, "text", None):
                piece = event.text
            elif getattr(event, "candidates", None):
                # ÏùºÎ∂Ä Ïù¥Î≤§Ìä∏Îäî delta ÌòïÌÉúÎ°ú Îì§Ïñ¥ÏôÄÏÑú textÍ∞Ä ÎπÑÏñ¥ ÏûàÏùå
                for c in event.candidates:
                    # Í∞Å candidateÏùò contentÏóêÏÑú Ï∂îÍ∞Ä ÌÖçÏä§Ìä∏Î•º ÏïàÏ†ÑÌïòÍ≤å Ï∂îÏ∂ú
                    try:
                        piece += "".join([p.text or "" for p in c.content.parts])
                    except Exception:
                        pass

            if piece:
                full_text += piece

        # 2) ÏµúÏ¢Ö Ìï¥ÏÑù (finish_reason/blocked Ïó¨Î∂Ä ÌôïÏù∏)
        try:
            stream.resolve()  # ÏµúÏ¢Ö ÏÉÅÌÉú/Î©îÌÉÄ ÌôïÎ≥¥
        except Exception:
            # resolveÏóêÏÑú Ïò§Î•òÍ∞Ä ÎÇòÎèÑ Î≥∏Î¨∏Ïù¥ ÏûàÏúºÎ©¥ Í≥ÑÏÜç ÏßÑÌñâ
            pass

        if not full_text:
            placeholder.warning("ÏùëÎãµÏù¥ ÎπÑÏñ¥ ÏûàÏäµÎãàÎã§. Îã§Ïãú ÏãúÎèÑÌï¥ Ï£ºÏÑ∏Ïöî.")

        # finish_reason/blocked ÏïàÎÇ¥
        try:
            cand0 = stream.candidates[0]
            fr = getattr(cand0, "finish_reason", None)
            block = getattr(cand0, "safety_ratings", None)
        except Exception:
            fr, block = None, None

        # 3) ÏûòÎ¶º/Ï∞®Îã® ÏïàÎÇ¥ + Ïù¥Ïñ¥Ïì∞Í∏∞ Î≤ÑÌäº
        if fr == "MAX_TOKENS":
            st.info("‚ÑπÔ∏è ÏùëÎãµÏù¥ Í∏∏Ïñ¥ Ï§ëÍ∞ÑÏóê ÏûòÎ†∏Ïñ¥Ïöî. ÏïÑÎûò Î≤ÑÌäºÏúºÎ°ú Ïù¥Ïñ¥ÏÑú ÏÉùÏÑ±Ìï† Ïàò ÏûàÏñ¥Ïöî.")
            if st.button("‚ûï Ïù¥Ïñ¥ÏÑú Îçî ÏÉùÏÑ±"):
                continue_from(full_text, prompt, gmodel, cfg)
        elif fr == "SAFETY":
            st.warning("‚ö†Ô∏è ÏïàÏ†Ñ ÌïÑÌÑ∞Î°ú ÏùºÎ∂Ä ÎÇ¥Ïö©Ïù¥ Ïà®Í≤®Ï°åÏùÑ Ïàò ÏûàÏñ¥Ïöî. ÌëúÌòÑÏùÑ Îã§Îì¨Ïñ¥ Îã§Ïãú ÏãúÎèÑÌï¥Î≥¥ÏÑ∏Ïöî.")

        status_placeholder.success("‚úÖ Ï†ÑÎûµ ÏÉùÏÑ±Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.")
        return full_text

    except Exception as e:
        status_placeholder.error("üö® Ï†ÑÎûµ ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.")
        st.error(
            "üö® Gemini ÏùëÎãµ ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\n\n"
            f"**ÏóêÎü¨ Ïú†Ìòï**: {type(e).__name__}\n"
            f"**Î©îÏãúÏßÄ**: {e}\n\n"
            "‚Ä¢ API Key/Î™®Îç∏ Ïù¥Î¶ÑÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\n"
            "‚Ä¢ ÏùºÏãúÏ†ÅÏù∏ ÎÑ§Ìä∏ÏõåÌÅ¨/ÏÑúÎπÑÏä§ Ïù¥ÏäàÏùº Ïàò ÏûàÏäµÎãàÎã§. Ïû†Ïãú ÌõÑ Îã§Ïãú ÏãúÎèÑÌï¥ Ï£ºÏÑ∏Ïöî."
        )
        return None


def continue_from(previous_text: str, original_prompt: str, gmodel, cfg):
    """
    MAX_TOKENSÎ°ú ÏûòÎ†∏ÏùÑ Îïå Ïù¥Ïñ¥Ïì∞Í∏∞. ÏõêÎ≥∏ Î¨∏Îß•ÏùÑ Í∞ÑÎã®Ìûà ÏöîÏïΩ¬∑Î≥µÏõêÌï¥ Ïó∞ÏÜçÏÑ± Ïú†ÏßÄ.
    """
    followup_prompt = (
        "ÏïÑÎûò Ï¥àÏïàÏùò Ïù¥Ïñ¥ÏßÄÎäî ÎÇ¥Ïö©ÏùÑ Í∞ôÏùÄ ÌÜ§/ÏÑúÏãùÏúºÎ°ú Í≥ÑÏÜç ÏûëÏÑ±ÌïòÏÑ∏Ïöî. "
        "Î∂àÌïÑÏöîÌïú Î∞òÎ≥µ ÏóÜÏù¥ Phase ÎÇòÎ®∏ÏßÄÏôÄ KPI, Ïã§Ìñâ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏Î•º ÎßàÏ†Ä Ï±ÑÏõåÏ£ºÏÑ∏Ïöî.\n\n"
        "=== ÏßÄÍ∏àÍπåÏßÄ ÏÉùÏÑ±Îêú Ï¥àÏïà ===\n"
        f"{previous_text}\n"
        "=== ÏõêÎûòÏùò ÏöîÍµ¨ÏÇ¨Ìï≠ ===\n"
        f"{original_prompt}\n"
    )

    try:
        stream2 = gmodel.generate_content(followup_prompt, generation_config=cfg, stream=True)
        placeholder = st.empty()
        full2 = ""
        for ev in stream2:
            if getattr(ev, "text", None):
                full2 += ev.text
                placeholder.markdown(full2 + "‚ñå")
        placeholder.markdown(full2)
        st.session_state.chat_history.append({"role": "assistant", "content": full2})
    except Exception as e:
        st.error(
            "üö® Ïù¥Ïñ¥Ïì∞Í∏∞ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\n\n"
            f"**ÏóêÎü¨ Ïú†Ìòï**: {type(e).__name__}\n"
            f"**Î©îÏãúÏßÄ**: {e}"
        )

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 6. ÌéòÎ•¥ÏÜåÎÇò Îß§Ïπ≠
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def find_persona(ÏóÖÏ¢Ö, ÌîÑÎûúÏ∞®Ïù¥Ï¶à, Ï†êÌè¨Ïó∞Î†π="ÎØ∏ÏÉÅ", Í≥†Í∞ùÏó∞Î†πÎåÄ="ÎØ∏ÏÉÅ", Í≥†Í∞ùÌñâÎèô="ÎØ∏ÏÉÅ"):
    for p in personas:
        if p["ÏóÖÏ¢Ö"] == ÏóÖÏ¢Ö and p["ÌîÑÎûúÏ∞®Ïù¥Ï¶àÏó¨Î∂Ä"] == ÌîÑÎûúÏ∞®Ïù¥Ï¶à:
            return p
    return None  # None Í∑∏ÎåÄÎ°ú Î∞òÌôò

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 7. Streamlit UI ÏÑ§Ï†ï
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(page_title="AI ÎßàÏºÄÌåÖ Ïª®ÏÑ§ÌÑ¥Ìä∏", layout="wide")
st.title("üí¨ AI ÎßàÏºÄÌåÖ Ïª®ÏÑ§ÌÑ¥Ìä∏")

if st.button("üîÑ ÏÉà ÏÉÅÎã¥ ÏãúÏûë"):
    st.session_state.clear()
    st.rerun()

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "info" not in st.session_state:
    st.session_state.info = {}
if "initialized" not in st.session_state:
    st.session_state.initialized = False

if not st.session_state.initialized:
    with st.chat_message("assistant"):
        st.markdown(
            "ÏïàÎÖïÌïòÏÑ∏Ïöî üëã Ï†ÄÎäî **AI ÎßàÏºÄÌåÖ Ïª®ÏÑ§ÌÑ¥Ìä∏**ÏûÖÎãàÎã§.\n\n"
            "ÏÉÅÏ†êÎ™ÖÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏãúÎ©¥ ÏóÖÏ¢ÖÍ≥º ÌîÑÎûúÏ∞®Ïù¥Ï¶à Ïó¨Î∂ÄÎ•º Î∂ÑÏÑùÌïòÍ≥†, "
            "Î™á Í∞ÄÏßÄ ÏßàÎ¨∏ÏùÑ ÌÜµÌï¥ ÎßûÏ∂§Ìòï ÎßàÏºÄÌåÖ Ï†ÑÎûµÏùÑ Ï†úÏïàÎìúÎ¶¥Í≤åÏöî.\n\n"
            "Ïòà: `ÍµêÏ¥åÏπòÌÇ®`, `ÌååÎ¶¨Î∞îÍ≤åÎú®`, `Ïπ¥ÌéòÌñâÎãπÏ†ê`, `ÏôïÏã≠Î¶¨ÎèºÏßÄÍµ≠Î∞•`"
        )
    st.session_state.initialized = True

for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        if msg.get("type") == "strategy":
            message_container = st.container()
            render_strategy_payload(msg.get("data", {}), message_container, prefix=msg.get("id", "history"))
        else:
            st.markdown(msg["content"])

user_input = st.chat_input("ÏÉÅÏ†êÎ™ÖÏùÑ ÏûÖÎ†•ÌïòÍ±∞ÎÇò ÏßàÎ¨∏Ïóê ÎãµÌï¥Ï£ºÏÑ∏Ïöî...")

def add_message(role, content=None, **kwargs):
    message = {"role": role}
    if kwargs.get("type") == "strategy":
        message["type"] = "strategy"
        message["data"] = kwargs.get("data", {})
        message["id"] = kwargs.get("id", str(uuid.uuid4()))
        message["raw"] = kwargs.get("raw")
    else:
        message["content"] = content if content is not None else ""
    st.session_state.chat_history.append(message)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 8. ÎåÄÌôî Î°úÏßÅ
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if user_input:
    add_message("user", user_input)

    # ‚ë† ÏÉÅÏ†êÎ™Ö
    if "ÏÉÅÏ†êÎ™Ö" not in st.session_state.info:
        name = user_input.strip()
        st.session_state.info["ÏÉÅÏ†êÎ™Ö"] = name
        st.session_state.info["ÏóÖÏ¢Ö"] = classify_hpsn_mct(name)
        st.session_state.info["ÌîÑÎûúÏ∞®Ïù¥Ï¶àÏó¨Î∂Ä"] = "ÌîÑÎûúÏ∞®Ïù¥Ï¶à" if is_franchise(name) else "Í∞úÏù∏Ï†êÌè¨"

        add_message(
            "assistant",
            f"'{name}'ÏùÄ(Îäî) **{st.session_state.info['ÏóÖÏ¢Ö']} ÏóÖÏ¢Ö**Ïù¥Î©∞ "
            f"**{st.session_state.info['ÌîÑÎûúÏ∞®Ïù¥Ï¶àÏó¨Î∂Ä']}**Î°ú Ï∂îÏ†ïÎê©ÎãàÎã§. üè™\n\n"
            "Í∞úÏóÖ ÏãúÍ∏∞Í∞Ä Ïñ∏Ï†úÏù∏Í∞ÄÏöî? (Ïòà: 6Í∞úÏõî Ï†Ñ, 2ÎÖÑ Ï†Ñ)"
        )
        st.rerun()

    # ‚ë° Í∞úÏóÖ ÏãúÍ∏∞
    elif "Ï†êÌè¨Ïó∞Î†π" not in st.session_state.info:
        months = re.findall(r"\d+", user_input)
        months = int(months[0]) if months else 0
        if months <= 12:
            st.session_state.info["Ï†êÌè¨Ïó∞Î†π"] = "Ïã†Í∑ú"
        elif months <= 24:
            st.session_state.info["Ï†êÌè¨Ïó∞Î†π"] = "Ï†ÑÌôòÍ∏∞"
        else:
            st.session_state.info["Ï†êÌè¨Ïó∞Î†π"] = "Ïò§ÎûòÎêú"

        add_message("assistant", "Ï¢ãÏïÑÏöî üëç Ï£ºÏöî Í≥†Í∞ùÏ∏µÏùÄ Ïñ¥Îñ§ Ïó∞Î†πÎåÄÏù∏Í∞ÄÏöî? (20ÎåÄ / 30~40ÎåÄ / 50ÎåÄ Ïù¥ÏÉÅ)")
        st.rerun()

    # ‚ë¢ Í≥†Í∞ù Ïó∞Î†πÎåÄ
    elif "Í≥†Í∞ùÏó∞Î†πÎåÄ" not in st.session_state.info:
        txt = user_input
        if "20" in txt:
            st.session_state.info["Í≥†Í∞ùÏó∞Î†πÎåÄ"] = "20ÎåÄ Ïù¥Ìïò Í≥†Í∞ù Ï§ëÏã¨"
        elif "30" in txt or "40" in txt:
            st.session_state.info["Í≥†Í∞ùÏó∞Î†πÎåÄ"] = "30~40ÎåÄ Í≥†Í∞ù Ï§ëÏã¨"
        else:
            st.session_state.info["Í≥†Í∞ùÏó∞Î†πÎåÄ"] = "50ÎåÄ Ïù¥ÏÉÅ Í≥†Í∞ù Ï§ëÏã¨"

        add_message("assistant", "ÎßàÏßÄÎßâÏúºÎ°ú, Í≥†Í∞ù Ïú†ÌòïÏùÄ Ïñ¥Îñ§ Ìé∏Ïù∏Í∞ÄÏöî? (ÏâºÌëúÎ°ú Íµ¨Î∂Ñ Í∞ÄÎä•: Ïû¨Î∞©Î¨∏, Ïã†Í∑ú, ÏßÅÏû•Ïù∏, Ïú†Îèô, Í±∞Ï£º)")
        st.rerun()

    # ‚ë£ Í≥†Í∞ùÌñâÎèô (Îã§Ï§ë ÏûÖÎ†• Ïú†Ïó∞ ÌååÏã±)
    elif "Í≥†Í∞ùÌñâÎèô" not in st.session_state.info:
        txt = user_input.lower()
        parts = re.split(r"[,/+\s]*(?:Î∞è|ÏôÄ|Í∑∏Î¶¨Í≥†)?[,/+\s]*", txt)
        parts = [p for p in parts if p]

        behaviors = []
        for p in parts:
            if "Ïû¨" in p or "Îã®Í≥®" in p:
                behaviors.append("Ïû¨Î∞©Î¨∏ Í≥†Í∞ù")
            if "Ïã†" in p or "ÏÉà" in p:
                behaviors.append("Ïã†Í∑ú Í≥†Í∞ù")
            if "Í±∞Ï£º" in p or "Ï£ºÎØº" in p:
                behaviors.append("Í±∞Ï£º Í≥†Í∞ù")
            if "ÏßÅÏû•" in p or "Ïò§ÌîºÏä§" in p or "ÌöåÏÇ¨" in p:
                behaviors.append("ÏßÅÏû•Ïù∏ Í≥†Í∞ù")
            if "Ïú†Îèô" in p or "ÏßÄÎÇò" in p or "Í¥ÄÍ¥ë" in p:
                behaviors.append("Ïú†Îèô Í≥†Í∞ù")

        behaviors = list(set(behaviors)) or ["ÏùºÎ∞ò Í≥†Í∞ù"]
        st.session_state.info["Í≥†Í∞ùÌñâÎèô"] = " + ".join(behaviors)

        # ... Í≥†Í∞ùÌñâÎèôÍπåÏßÄ ÏàòÏßëÎêú Îí§:
        info = st.session_state.info
        persona = find_persona(
            info["ÏóÖÏ¢Ö"], info["ÌîÑÎûúÏ∞®Ïù¥Ï¶àÏó¨Î∂Ä"],
            info["Ï†êÌè¨Ïó∞Î†π"], info["Í≥†Í∞ùÏó∞Î†πÎåÄ"], info["Í≥†Í∞ùÌñâÎèô"]
        )

        # ‚ë† persona prompt ÎòêÎäî ‚ë° fallback prompt
        if persona and "prompt" in persona:
            prompt = ensure_data_evidence(persona["prompt"])
        else:
            prompt = ensure_data_evidence(
                "Îã§Ïùå ÏÉÅÏ†ê Ï†ïÎ≥¥Î•º Í∏∞Î∞òÏúºÎ°ú 3~5Îã®Í≥Ñ PhaseÎ≥Ñ ÎßûÏ∂§Ìòï ÎßàÏºÄÌåÖ Ï†ÑÎûµÏùÑ Ï†úÏïàÌïòÏÑ∏Ïöî.\n"
                "Í∞Å PhaseÎäî Î™©Ìëú, ÌïµÏã¨ Ïï°ÏÖò(Ï±ÑÎÑê¬∑Ïª®ÌÖêÏ∏†¬∑Ïò§Ìçº), ÏòàÏÇ∞Î≤îÏúÑ, ÏòàÏÉÅ KPI, Îã§Ïùå PhaseÎ°ú ÎÑòÏñ¥Í∞ÄÎäî Í∏∞Ï§ÄÏùÑ Ìè¨Ìï®ÌïòÏÑ∏Ïöî.\n\n"
                f"- ÏóÖÏ¢Ö: {info['ÏóÖÏ¢Ö']}\n"
                f"- ÌòïÌÉú: {info['ÌîÑÎûúÏ∞®Ïù¥Ï¶àÏó¨Î∂Ä']}\n"
                f"- Ï†êÌè¨Ïó∞Î†π: {info['Ï†êÌè¨Ïó∞Î†π']}\n"
                f"- Ï£ºÏöî Í≥†Í∞ùÏó∞Î†πÎåÄ: {info['Í≥†Í∞ùÏó∞Î†πÎåÄ']}\n"
                f"- Í≥†Í∞ùÌñâÎèô ÌäπÏÑ±: {info['Í≥†Í∞ùÌñâÎèô']}\n"
                "ÏùëÎãµÏùÄ Î∂àÎ¶øÍ≥º ÌëúÎ•º Ï†ÅÏ†àÌûà ÏÑûÏñ¥ Í∞ÑÍ≤∞ÌïòÍ≤å ÏûëÏÑ±ÌïòÏÑ∏Ïöî."
            )

        #with st.expander("üìú ÌîÑÎ°¨ÌîÑÌä∏ Î≥¥Í∏∞"):
        #    st.code(prompt, language="markdown")

        add_message("assistant", "Ïù¥Ï†ú AI ÏÉÅÎã¥ÏÇ¨Í∞Ä ÎßûÏ∂§Ìòï ÎßàÏºÄÌåÖ Ï†ÑÎûµÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§... ‚è≥")

        with st.chat_message("assistant"):
            st.markdown("### üìà ÏÉùÏÑ±Îêú ÎßàÏºÄÌåÖ Ï†ÑÎûµ Í≤∞Í≥º")
            content_placeholder = st.empty()
            result = stream_gemini(prompt, output_placeholder=content_placeholder)  # ‚¨ÖÔ∏è Ïä§Ìä∏Î¶¨Î∞ç Ï∂úÎ†•
            if result:
                payload = parse_strategy_payload(result)
                if payload:
                    message_id = str(uuid.uuid4())
                    content_placeholder.empty()
                    strategy_container = st.container()
                    render_strategy_payload(payload, strategy_container, prefix=message_id)
                    add_message(
                        "assistant",
                        type="strategy",
                        data=payload,
                        id=message_id,
                        raw=result,
                    )
                else:
                    summary_points = extract_executive_summary(result)
                    if summary_points:
                        summary_markdown = "#### ‚ö° ÌïµÏã¨ ÏöîÏïΩ\n\n" + "\n".join(
                            f"- {point}" for point in summary_points
                        )
                        content_placeholder.markdown(summary_markdown)
                        add_message("assistant", summary_markdown)
                    else:
                        fallback_notice = (
                            "Íµ¨Ï°∞ÌôîÎêú ÏùëÎãµÏùÑ ÌëúÏãúÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§. Îã§Ïãú ÏãúÎèÑÌïòÍ±∞ÎÇò ÌîÑÎ°¨ÌîÑÌä∏Î•º Ï°∞Ï†ïÌï¥ Ï£ºÏÑ∏Ïöî."
                        )
                        content_placeholder.warning(fallback_notice)
                        add_message("assistant", fallback_notice)
