import os
import re
import json
import logging
import time
import uuid
import streamlit as st
import google.generativeai as genai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ë¡œê·¸ ë° ê²½ê³  ì–µì œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.getLogger("google.auth").setLevel(logging.ERROR)
os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GLOG_minloglevel"] = "3"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Gemini API ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
else:
    st.warning("âš ï¸ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Streamlit secretsì— ì¶”ê°€í•˜ì„¸ìš”.")

DEFAULT_MODEL = "gemini-2.5-flash"
DATA_EVIDENCE_GUIDE = (
    "\n\nì¶”ê°€ ì§€ì¹¨:\n"
    "- ê° ì œì•ˆì—ëŠ” ë°ì´í„° ê·¼ê±°(í‘œ/ì§€í‘œ/ê·œì¹™ ë“±)ë¥¼ í•¨ê»˜ í‘œê¸°í•˜ì„¸ìš”.\n"
    "- ê°€ëŠ¥í•œ ê²½ìš° ê°„ë‹¨í•œ í‘œë‚˜ ì§€í‘œ ìˆ˜ì¹˜ë¥¼ í™œìš©í•´ ê·¼ê±°ë¥¼ ëª…í™•íˆ ë³´ì—¬ì£¼ì„¸ìš”."
)

STRUCTURED_RESPONSE_GUIDE = (
    "\n\nì‘ë‹µ í˜•ì‹ ì§€ì¹¨(ì¤‘ìš”):\n"
    "1. ë°˜ë“œì‹œ ë°±í‹±ì´ë‚˜ ì£¼ì„ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
    "2. JSONì€ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ì„¸ìš”.\n"
    "{\n"
    '  \"objective\": \"ìµœìš°ì„  ë§ˆì¼€íŒ… ëª©í‘œë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\",\n'
    '  \"phase_titles\": [\"Phase 1: â€¦\", \"Phase 2: â€¦\", \"Phase 3: â€¦\"],\n'
    '  \"channel_summary\": [\n'
    '    {\n'
    '      \"channel\": \"ì±„ë„ëª…\",\n'
    '      \"phase_title\": \"ì—°ê²°ëœ Phase ì œëª©\",\n'
    '      \"reason\": \"ì¶”ì²œ ì´ìœ ì™€ ê¸°ëŒ€ íš¨ê³¼\",\n'
    '      \"data_evidence\": \"ê´€ë ¨ ìˆ˜ì¹˜/ê·œì¹™ ë“± ë°ì´í„° ê·¼ê±°\"\n'
    "    }\n"
    "  ],\n"
    '  \"phases\": [\n'
    "    {\n"
    '      \"title\": \"Phase 1: â€¦\",\n'
    '      \"goal\": \"êµ¬ì²´ì ì¸ ëª©í‘œ\",\n'
    '      \"focus_channels\": [\"í•µì‹¬ ì±„ë„ 1\", \"í•µì‹¬ ì±„ë„ 2\"],\n'
    '      \"actions\": [\n'
    "        {\n"
    '          \"task\": \"ì²´í¬ë°•ìŠ¤ì— ë“¤ì–´ê°ˆ ì‹¤í–‰ í•­ëª©\",\n'
    '          \"owner\": \"ë‹´ë‹¹ ì—­í• (ì˜ˆ: ì ì£¼, ìŠ¤íƒœí”„)\",\n'
    '          \"supporting_data\": \"ì„ íƒ) ê´€ë ¨ ë°ì´í„° ê·¼ê±°\"\n'
    "        }\n"
    "      ],\n"
    '      \"metrics\": [\"ì„±ê³¼ KPI\"],\n'
    '      \"next_phase_criteria\": [\"ë‹¤ìŒ Phaseë¡œ ë„˜ì–´ê°€ê¸° ìœ„í•œ ì •ëŸ‰/ì •ì„± ê¸°ì¤€\"],\n'
    '      \"data_evidence\": [\"Phase ì „ëµì„ ë’·ë°›ì¹¨í•˜ëŠ” ê·¼ê±°\"]\n'
    "    }\n"
    "  ],\n"
    '  \"risks\": [\"ì£¼ìš” ë¦¬ìŠ¤í¬ì™€ ëŒ€ì‘ ìš”ì•½\"],\n'
    '  \"monitoring_cadence\": \"ëª¨ë‹ˆí„°ë§ ì£¼ê¸°ì™€ ì±…ì„ì\"\n'
    "}\n"
    "3. PhaseëŠ” ì‹œê°„ ìˆœì„œë¥¼ ì§€í‚¤ê³  Phase 1ì˜ action í•­ëª©ì€ ìµœì†Œ 3ê°œë¥¼ í¬í•¨í•˜ì„¸ìš”.\n"
    "4. ëª¨ë“  reason, supporting_data, data_evidenceì—ëŠ” ì •ëŸ‰ ìˆ˜ì¹˜ë‚˜ ê·œì¹™ì  ê·¼ê±°ë¥¼ ëª…ì‹œí•˜ì„¸ìš”."
)

FOLLOWUP_RESPONSE_GUIDE = (
    "\n\nì‘ë‹µ í˜•ì‹ ì§€ì¹¨(ì¤‘ìš”):\n"
    "1. ë°˜ë“œì‹œ ë°±í‹±ì´ë‚˜ ì£¼ì„ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
    "2. JSONì€ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ì„¸ìš”.\n"
    "{\n"
    '  "summary_points": ["í•µì‹¬ ìš”ì•½ 1", "í•µì‹¬ ìš”ì•½ 2"],\n'
    '  "detailed_guidance": "ìš”ì•½ì„ í™•ì¥í•˜ëŠ” ìƒì„¸ ì¡°ì–¸",\n'
    '  "evidence_mentions": ["ê´€ë ¨ ê·¼ê±° ë˜ëŠ” KPI ì–¸ê¸‰"],\n'
    '  "suggested_question": "ë‹¤ìŒìœ¼ë¡œ ì´ì–´ì§ˆ ê°„ë‹¨í•œ í•œ ë¬¸ì¥ ì§ˆë¬¸"\n'
    "}\n"
    "3. summary_pointsëŠ” ìµœëŒ€ 2ê°œ, ê° í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ê³  ì¤‘í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
    "4. evidence_mentionsëŠ” ìµœëŒ€ 3ê°œ ì´ë‚´ì˜ ë¶ˆë¦¿ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ìˆ«ìë‚˜ ì§€í‘œê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.\n"
    "5. detailed_guidanceëŠ” ê¸°ì¡´ ì „ëµì„ ì¬í•´ì„í•˜ë©° ë°ì´í„° ê·¼ê±°ë¥¼ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ë˜ ì‰¬ìš´ ì–´íœ˜ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n"
    "6. suggested_questionì€ ì‚¬ìš©ìê°€ ë°”ë¡œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§§ì€ í›„ì† ì§ˆë¬¸ 1ê°œë§Œ ì œì•ˆí•˜ì„¸ìš”."
)


TOOL_SUGGESTION_GUIDE = (
    "\n\nì‘ë‹µ í˜•ì‹ ì§€ì¹¨(ì¤‘ìš”):\n"
    "1. ë°˜ë“œì‹œ ë°±í‹±ì´ë‚˜ ì£¼ì„ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
    "2. JSONì€ ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ì„¸ìš”.\n"
    "{\n"
    '  "tools": [\n'
    "    {\n"
    '      "name": "ë„êµ¬ ì´ë¦„",\n'
    '      "category": "ì˜ˆ: SNS ê´€ë¦¬ / CRM / ì„¤ë¬¸",\n'
    '      "purpose": "Phase 1 ëª©í‘œì™€ ì—°ê²°ëœ í™œìš© ëª©ì ",\n'
    '      "how_to_use": ["1ë‹¨ê³„", "2ë‹¨ê³„", "3ë‹¨ê³„"],\n'
    '      "tips": ["í™œìš© íŒ"],\n'
    '      "kpi": ["ì—°ê´€ KPI"],\n'
    '      "cost": "ë¬´ë£Œ/ìœ ë£Œ ì—¬ë¶€ ë° ê°€ê²© ë²”ìœ„",\n'
    '      "korean_support": "í•œêµ­ì–´ ì§€ì› ì—¬ë¶€"\n'
    "    }\n"
    "  ],\n"
    '  "notes": ["ì¶”ê°€ ì°¸ê³ ì‚¬í•­"]\n'
    "}\n"
    "3. how_to_useëŠ” 2~3ë‹¨ê³„ë¡œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ìˆœì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
    "4. ë„êµ¬ëŠ” ì†Œìƒê³µì¸ì´ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆí•˜ê³ , ê°€ëŠ¥í•˜ë©´ ë¬´ë£Œ ë˜ëŠ” ì €ë¹„ìš© ì˜µì…˜ì„ ìš°ì„ í•˜ì„¸ìš”."
)


def ensure_data_evidence(prompt: str) -> str:
    """í”„ë¡¬í”„íŠ¸ì— ë°ì´í„° ê·¼ê±° ì§€ì¹¨ì´ ì—†ìœ¼ë©´ ì¶”ê°€."""
    updated = prompt.rstrip()
    if "ë°ì´í„° ê·¼ê±°" not in updated:
        updated += DATA_EVIDENCE_GUIDE
    if '"phase_titles"' not in updated and "ì‘ë‹µ í˜•ì‹ ì§€ì¹¨(ì¤‘ìš”)" not in updated:
        updated += STRUCTURED_RESPONSE_GUIDE
    return updated


def extract_executive_summary(markdown_text: str, max_points: int = 4):
    """ìƒì„±ëœ ì „ëµ ë³¸ë¬¸ì—ì„œ ìš”ì•½ ì„¹ì…˜ì˜ í•µì‹¬ ë¶ˆë¦¿ì„ ì¶”ì¶œ."""
    lines = markdown_text.splitlines()
    summary_lines = []

    def clean_bullet(line):
        stripped = line.strip()
        if not stripped:
            return None
        bullet_match = re.match(r"^[-\*\u2022]\s*(.+)", stripped)
        if bullet_match:
            return bullet_match.group(1).strip()
        numbered_match = re.match(r"^\d+[.)]\s*(.+)", stripped)
        if numbered_match:
            return numbered_match.group(1).strip()
        return None

    heading_pattern = re.compile(r"#{1,6}\s*ìš”ì•½")
    start_idx = next(
        (idx for idx, line in enumerate(lines) if heading_pattern.match(line.strip())),
        None,
    )

    if start_idx is not None:
        for line in lines[start_idx + 1 :]:
            stripped = line.strip()
            if stripped.startswith("#"):
                break
            cleaned = clean_bullet(stripped)
            if cleaned:
                summary_lines.append(cleaned)
            if len(summary_lines) >= max_points:
                break

    if not summary_lines:
        for line in lines:
            cleaned = clean_bullet(line)
            if cleaned:
                summary_lines.append(cleaned)
            if len(summary_lines) >= max_points:
                break

    if not summary_lines:
        collapsed = re.sub(r"\s+", " ", markdown_text)
        sentences = re.split(r"(?<=[.!?])\s", collapsed)
        for sentence in sentences:
            cleaned = sentence.strip()
            if cleaned:
                summary_lines.append(cleaned)
            if len(summary_lines) >= max_points:
                break

    return summary_lines


def strip_json_artifacts(text: str) -> str:
    """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì„ì¼ ìˆ˜ ìˆëŠ” ë¶ˆí•„ìš”í•œ ë¬¸ìë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜ JSON ë¬¸ìì—´ë§Œ ë‚¨ê¸´ë‹¤."""
    cleaned = text.strip().replace("â–Œ", "")
    fence_pattern = re.compile(r"^```(?:json)?\s*|\s*```$")
    cleaned = fence_pattern.sub("", cleaned)
    return cleaned.strip()


def parse_strategy_payload(raw_text: str):
    """JSON ì‘ë‹µì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±. ì‹¤íŒ¨ ì‹œ None."""
    candidate = strip_json_artifacts(raw_text)
    if not candidate:
        return None
    try:
        return json.loads(candidate)
    except json.JSONDecodeError:
        return None


def parse_followup_payload(raw_text: str):
    """í›„ì† ì§ˆì˜ ì‘ë‹µìš© JSONì„ íŒŒì‹±."""
    candidate = strip_json_artifacts(raw_text)
    if not candidate:
        return None
    try:
        data = json.loads(candidate)
    except json.JSONDecodeError:
        return None
    if not isinstance(data, dict):
        return None
    return data


def build_phase_followup_question(phase: dict) -> str:
    """Phase 1 ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ì²œ í›„ì† ì§ˆë¬¸ì„ ìƒì„±."""
    if not isinstance(phase, dict):
        return "Phase 1 ì „ëµì„ ì‹¤í–‰í•˜ë©´ì„œ ì¶”ê°€ë¡œ ì ê²€í•´ì•¼ í•  ë¶€ë¶„ì„ ì•Œë ¤ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?"

    focus_channels = phase.get("focus_channels") or []
    actions = phase.get("actions") or []
    goal = (phase.get("goal") or "").strip()

    primary_channel = focus_channels[0].strip() if focus_channels else ""
    primary_action = ""
    if actions and isinstance(actions[0], dict):
        primary_action = (actions[0].get("task") or "").strip()

    if primary_channel and primary_action:
        return f"{primary_channel} ì±„ë„ì—ì„œ '{primary_action}'ì„ ì‹¤í–‰í•  ë•Œ ë” ì¤€ë¹„í•´ì•¼ í•  ì½˜í…ì¸  ì•„ì´ë””ì–´ê°€ ìˆì„ê¹Œìš”?"
    if primary_channel and goal:
        return f"{primary_channel} ì±„ë„ì„ í™œìš©í•´ '{goal}' ëª©í‘œë¥¼ ë‹¬ì„±í•˜ë ¤ë©´ ì¶”ê°€ë¡œ ì–´ë–¤ ì‹¤í–‰ íŒì´ í•„ìš”í• ê¹Œìš”?"
    if goal:
        return f"Phase 1 ëª©í‘œì¸ '{goal}'ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë¨¼ì € í™•ì¸í•´ì•¼ í•  ì²´í¬í¬ì¸íŠ¸ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"
    if primary_channel:
        return f"{primary_channel} ì±„ë„ ìš´ì˜ ì‹œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì•„ì´ë””ì–´ê°€ ìˆì„ê¹Œìš”?"
    return "Phase 1 ì „ëµì„ ì‹¤í–‰í•˜ë©´ì„œ ì¶”ê°€ë¡œ ì ê²€í•´ì•¼ í•  ë¶€ë¶„ì„ ì•Œë ¤ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?"


def build_phase_tool_prompt(strategy_payload: dict, phase: dict, store_info: dict | None) -> str:
    """Phase 1 ì „ëµì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¼€íŒ… ë„êµ¬ ì¶”ì²œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±."""
    store_info = store_info or {}
    phase = phase if isinstance(phase, dict) else {}
    info_fields = ["ìƒì ëª…", "ì—…ì¢…", "í”„ëœì°¨ì´ì¦ˆì—¬ë¶€", "ì í¬ì—°ë ¹", "ê³ ê°ì—°ë ¹ëŒ€", "ê³ ê°í–‰ë™"]
    info_lines = [f"- {field}: {store_info[field]}" for field in info_fields if store_info.get(field)]
    info_block = "\n".join(info_lines) if info_lines else "- ì¶”ê°€ ìƒì  ì •ë³´ ì—†ìŒ"

    objective = (strategy_payload.get("objective") or "").strip() if isinstance(strategy_payload, dict) else ""
    focus_channels = phase.get("focus_channels") or []
    focus_block = ", ".join(
        fc.strip() for fc in focus_channels if isinstance(fc, str) and fc.strip()
    ) or "ë¯¸ì§€ì •"

    actions = phase.get("actions") or []
    action_lines = []
    for action in actions:
        if not isinstance(action, dict):
            continue
        label = (action.get("task") or "ì‘ì—… ë¯¸ì •").strip()
        owner = (action.get("owner") or "").strip()
        support = (action.get("supporting_data") or "").strip()
        meta_parts = []
        if owner:
            meta_parts.append(f"ë‹´ë‹¹ {owner}")
        if support:
            meta_parts.append(f"ê·¼ê±° {support}")
        meta_text = f" ({', '.join(meta_parts)})" if meta_parts else ""
        action_lines.append(f"- {label}{meta_text}")
    actions_block = "\n".join(action_lines) if action_lines else "- ë“±ë¡ëœ ì•¡ì…˜ ì—†ìŒ"

    metrics = phase.get("metrics") or []
    metrics_block = (
        "\n".join(f"- {m}" for m in metrics if isinstance(m, str) and m.strip())
        if metrics
        else "- ì •ì˜ëœ KPI ì—†ìŒ"
    )

    criteria = phase.get("next_phase_criteria") or []
    criteria_block = (
        "\n".join(f"- {c}" for c in criteria if isinstance(c, str) and c.strip())
        if criteria
        else "- ê¸°ì¤€ ë¯¸ì •"
    )

    evidence = phase.get("data_evidence") or []
    evidence_block = (
        "\n".join(f"- {e}" for e in evidence if isinstance(e, str) and e.strip())
        if evidence
        else "- ì¶”ê°€ ê·¼ê±° ì—†ìŒ"
    )

    prompt_lines = [
        "ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ë§ˆì¼€íŒ…ì„ ì§€ì›í•˜ëŠ” ì‹œë‹ˆì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.",
        "ì•„ë˜ Phase 1 ì „ëµì„ ì‹¤í–‰í•  ë•Œ ë„ì›€ì´ ë˜ëŠ” ì‹¤ë¬´ ë„êµ¬(SaaS, ë¶„ì„, ì½˜í…ì¸  ì œì‘, ìë™í™” ë“±)ë¥¼ ì¶”ì²œí•˜ì„¸ìš”.",
        "ë„êµ¬ëŠ” ë¬´ë£Œ ë˜ëŠ” ì €ë¹„ìš© ì˜µì…˜ì„ ìš°ì„  ì œì•ˆí•˜ê³ , ê° ë„êµ¬ë³„ë¡œ ëª©ì ê³¼ 2~3ë‹¨ê³„ ì‹¤í–‰ ê°€ì´ë“œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.",
        "ê° ë„êµ¬ì˜ ì—°ê´€ KPI, ë¹„ìš© ë²”ìœ„, í•œêµ­ì–´ ì§€ì› ì—¬ë¶€, í™œìš© ì‹œ ì£¼ì˜ì ë„ í•¨ê»˜ ì–¸ê¸‰í•˜ì„¸ìš”.",
        "",
        "=== ìƒì  ì •ë³´ ===",
        info_block,
        "",
        "=== ì „ëµ Objective ===",
        f"- {objective}" if objective else "- ì œê³µëœ Objective ì—†ìŒ",
        "",
        "=== Phase 1 ê°œìš” ===",
        f"- ì œëª©: {phase.get('title', 'Phase 1')}",
        f"- ëª©í‘œ: {phase.get('goal', 'ë¯¸ì •')}",
        f"- ì§‘ì¤‘ ì±„ë„: {focus_block}",
        "",
        "=== ì‹¤í–‰ ì•¡ì…˜ ===",
        actions_block,
        "",
        "=== ì£¼ìš” KPI ===",
        metrics_block,
        "",
        "=== ë‹¤ìŒ Phase ê¸°ì¤€ ===",
        criteria_block,
        "",
        "=== ë°ì´í„° ê·¼ê±° ===",
        evidence_block,
        TOOL_SUGGESTION_GUIDE,
    ]
    return "\n".join(prompt_lines)


def parse_tool_suggestions(raw_text: str) -> dict:
    """ë„êµ¬ ì¶”ì²œ JSONì„ íŒŒì‹±."""
    candidate = strip_json_artifacts(raw_text)
    if not candidate:
        return {"tools": [], "notes": [], "raw": raw_text.strip()}

    try:
        data = json.loads(candidate)
    except json.JSONDecodeError:
        return {"tools": [], "notes": [], "raw": raw_text.strip()}

    tools_data = data.get("tools") if isinstance(data, dict) else []
    normalized_tools = []
    if isinstance(tools_data, list):
        for item in tools_data:
            if not isinstance(item, dict):
                continue
            normalized_tools.append(
                {
                    "name": (item.get("name") or "").strip(),
                    "category": (item.get("category") or "").strip(),
                    "purpose": (item.get("purpose") or "").strip(),
                    "how_to_use": [
                        step.strip()
                        for step in (item.get("how_to_use") or [])
                        if isinstance(step, str) and step.strip()
                    ],
                    "tips": [
                        tip.strip()
                        for tip in (item.get("tips") or [])
                        if isinstance(tip, str) and tip.strip()
                    ],
                    "kpi": [
                        k.strip()
                        for k in (item.get("kpi") or [])
                        if isinstance(k, str) and k.strip()
                    ],
                    "cost": (item.get("cost") or "").strip(),
                    "korean_support": (item.get("korean_support") or "").strip(),
                }
            )

    notes_data = data.get("notes") if isinstance(data, dict) else []
    normalized_notes = [
        note.strip()
        for note in notes_data
        if isinstance(note, str) and note.strip()
    ]

    return {
        "tools": normalized_tools,
        "notes": normalized_notes,
        "raw": candidate.strip(),
    }


def format_tool_suggestions(parsed: dict) -> str:
    """ë„êµ¬ ì¶”ì²œ íŒŒì‹± ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜."""
    tools = parsed.get("tools") or []
    notes = parsed.get("notes") or []
    raw = (parsed.get("raw") or "").strip()

    if not tools and not notes:
        return raw

    lines = ["### ğŸ› ï¸ Phase 1 ë§ˆì¼€íŒ… ë„êµ¬ ì¶”ì²œ"]
    for tool in tools:
        name = tool.get("name") or "ë„êµ¬ ë¯¸ì •"
        meta_parts = [part for part in (tool.get("category"), tool.get("cost")) if part]
        meta_text = ", ".join(meta_parts)
        header = f"- **{name}**"
        if meta_text:
            header += f" ({meta_text})"
        purpose = tool.get("purpose")
        if purpose:
            header += f": {purpose}"
        lines.append(header)

        how_steps = tool.get("how_to_use") or []
        if how_steps:
            lines.append("  - í™œìš© ë‹¨ê³„:")
            for step in how_steps:
                lines.append(f"    - {step}")

        tips = tool.get("tips") or []
        if tips:
            lines.append(f"  - íŒ: {'; '.join(tips)}")

        kpi = tool.get("kpi") or []
        if kpi:
            lines.append(f"  - ì—°ê´€ KPI: {', '.join(kpi)}")

        korean_support = tool.get("korean_support")
        if korean_support:
            lines.append(f"  - í•œêµ­ì–´ ì§€ì›: {korean_support}")

    if notes:
        lines.append("\n**ì¶”ê°€ ë©”ëª¨**")
        for note in notes:
            lines.append(f"- {note}")

    return "\n".join(lines)


INFO_FIELD_ORDER = ["ìƒì ëª…", "ì í¬ì—°ë ¹", "ê³ ê°ì—°ë ¹ëŒ€", "ê³ ê°í–‰ë™"]
BUTTON_HINT = "\n\ní•„ìš”í•œ ì •ë³´ê°€ ì•„ë‹ˆì–´ë„ ì•„ë˜ 'ì´ëŒ€ë¡œ ì§ˆë¬¸' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì§€ê¸ˆ ì •ë³´ë¡œ ë°”ë¡œ ë‹µë³€ì„ ë“œë¦´ê²Œìš”."
DIRECT_RESPONSE_GUIDE = (
    "\n\në‹µë³€ ì§€ì¹¨:\n"
    "- ë¶ˆë¦¿ ëŒ€ì‹  1~2ê°œì˜ ì§§ì€ ë‹¨ë½ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n"
    "- ì¤‘í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
    "- ê°€ëŠ¥í•œ ê²½ìš° ìˆ«ìë‚˜ ê·œì¹™ ê°™ì€ ê·¼ê±°ë¥¼ ë¬¸ì¥ ì•ˆì— ì§ì ‘ ë…¹ì—¬ ì£¼ì„¸ìš”.\n"
    "- ì‹¤í–‰ ì•„ì´ë””ì–´ëŠ” êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.\n"
    "- ë§ˆì§€ë§‰ì—ëŠ” `ì¶”ì²œ í›„ì† ì§ˆë¬¸: â€¦` í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì´ì–´ì„œ ë¬¼ì–´ë³¼ ë§Œí•œ ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”."
)


def get_missing_info_fields(info: dict) -> list:
    """í•„ìˆ˜ ì •ë³´ ì¤‘ ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ í•­ëª©ì„ ë°˜í™˜."""
    missing = []
    for field in INFO_FIELD_ORDER:
        value = info.get(field)
        if not value:
            missing.append(field)
    return missing


def get_latest_strategy_message():
    """ì„¸ì…˜ ê¸°ë¡ì—ì„œ ê°€ì¥ ìµœì‹  ì „ëµ ë©”ì‹œì§€ë¥¼ ë°˜í™˜."""
    history = st.session_state.get("chat_history", [])
    for item in reversed(history):
        if item.get("type") == "strategy":
            return item
    return None


def build_followup_prompt(question: str, info: dict, strategy_payload: dict, raw_strategy: str) -> str:
    """ì´ì „ ì „ëµì„ ë¬¸ë§¥ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±."""
    info_keys = ["ìƒì ëª…", "ì—…ì¢…", "í”„ëœì°¨ì´ì¦ˆì—¬ë¶€", "ì í¬ì—°ë ¹", "ê³ ê°ì—°ë ¹ëŒ€", "ê³ ê°í–‰ë™"]
    info_lines = [
        f"- {key}: {info[key]}"
        for key in info_keys
        if key in info and info[key]
    ]
    info_block = "\n".join(info_lines) if info_lines else "- ì¶”ê°€ ìƒì  ì •ë³´ ì—†ìŒ"

    strategy_block = ""
    if strategy_payload:
        try:
            strategy_block = json.dumps(strategy_payload, ensure_ascii=False, indent=2)
        except (TypeError, ValueError):
            strategy_block = raw_strategy or ""
    else:
        strategy_block = raw_strategy or ""

    prompt = (
        "ë‹¹ì‹ ì€ ì¤‘ì†Œìƒê³µì¸ì„ ë•ëŠ” ì‹œë‹ˆì–´ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
        "ì´ë¯¸ ìƒì„±ëœ ì „ëµ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n"
        "ì „ëµì˜ Phase, ì±„ë„, ì‹¤í–‰ í•­ëª©, ë°ì´í„° ê·¼ê±°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¸ìš©í•˜ê³  í•„ìš” ì‹œ ê°„ë‹¨í•œ ì¶”ê°€ ì¡°ì–¸ì„ ë”í•˜ì„¸ìš”.\n"
        "ìƒˆ ì „ëµì„ ìƒˆë¡œ ì§œì§€ ë§ê³ , ê¸°ì¡´ ì „ëµì„ ì¬í•´ì„í•˜ê±°ë‚˜ ë³´ì™„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n"
        "ëª¨ë“  ì„¤ëª…ì€ ì¤‘í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n\n"
        "=== ìƒì  ê¸°ë³¸ ì •ë³´ ===\n"
        f"{info_block}\n\n"
        "=== ê¸°ì¡´ ì „ëµ(JSON) ===\n"
        f"{strategy_block}\n\n"
        "=== ì‚¬ìš©ì ì§ˆë¬¸ ===\n"
        f"{question}\n\n"
        "ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ì „ëµ ì •ë³´ë¥¼ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê·¼ê±°ë¡œ í™œìš©í•´ ì¡°ì–¸í•˜ì„¸ìš”.\n"
        "ë°ì´í„° ê·¼ê±° í•­ëª©ì´ë‚˜ KPIê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì–¸ê¸‰í•˜ê±°ë‚˜ ìˆ˜ì¹˜ë¡œ ë‹µë³€ì— ë°˜ì˜í•˜ì„¸ìš”."
        f"{FOLLOWUP_RESPONSE_GUIDE}"
    )
    return prompt


def build_direct_question_prompt(info: dict, question: str, missing_fields=None) -> str:
    """ìˆ˜ì§‘ëœ ì •ë³´ë§Œìœ¼ë¡œ ì§ì ‘ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±."""
    missing_fields = missing_fields or []
    info_lines = [
        f"- {field}: {info[field]}"
        for field in INFO_FIELD_ORDER
        if info.get(field)
    ]
    info_block = "\n".join(info_lines) if info_lines else "- ì œê³µëœ ì •ë³´ ì—†ìŒ"

    missing_note = ""
    if missing_fields:
        missing_note = (
            "\n\nì£¼ì˜: ì•„ì§ ë‹¤ìŒ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            + ", ".join(missing_fields)
            + "."
        )

    prompt = (
        "ë‹¹ì‹ ì€ ë™ë„¤ ìƒê¶Œì„ ë•ëŠ” ì‹œë‹ˆì–´ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ ìƒì  ì •ë³´ë¥¼ ì°¸ê³ í•´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì¡°ì–¸ì„ ì£¼ì„¸ìš”.\n"
        "ë‹µë³€ì€ ë¬¸ë‹¨ í˜•íƒœë¡œ ì‘ì„±í•˜ê³ , í•„ìš”í•œ ê²½ìš° ìˆ˜ì¹˜ë‚˜ ê·œì¹™ ê°™ì€ ê·¼ê±°ë¥¼ ë¬¸ì¥ ì•ˆì— ë…¹ì—¬ ì„¤ëª…í•˜ì„¸ìš”.\n"
        "ìƒˆë¡œìš´ ê°€ì •ì„ ë§Œë“¤ê¸°ë³´ë‹¤ëŠ” ì œê³µëœ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.\n\n"
        "=== ìƒì  ì •ë³´ ===\n"
        f"{info_block}\n\n"
        "=== ì‚¬ìš©ì ì§ˆë¬¸ ===\n"
        f"{question}\n"
        f"{missing_note}"
        f"{DIRECT_RESPONSE_GUIDE}"
    )
    return prompt


def default_suggested_question(info: dict, question: str) -> str:
    """ì§ˆë¬¸ì´ë‚˜ ìƒì  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ë³¸ í›„ì† ì§ˆë¬¸ì„ ë„ì¶œ."""
    text = (question or "").lower()
    if "ë‹¨ê³¨" in text or "ì¬ë°©ë¬¸" in text:
        return "ë‹¨ê³¨ ê³ ê°ì—ê²Œ ì¤„ë§Œí•œ í˜œíƒ ì•„ì´ë””ì–´ë„ ì•Œë ¤ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?"
    if "ë§¤ì¶œ" in text or "íŒë§¤" in text or "ì‹¤ì " in text:
        return "ë§¤ì¶œì„ ë” ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆëŠ” ì¶”ê°€ í”„ë¡œëª¨ì…˜ì´ ìˆì„ê¹Œìš”?"
    if "ì‹ ê·œ" in text or "ìƒˆ" in text:
        return "ì‹ ê·œ ì†ë‹˜ì„ ëŠ˜ë¦¬ë ¤ë©´ ì–´ë–¤ í™ë³´ ì±„ë„ì´ ì¢‹ì„ê¹Œìš”?"
    if "ê´‘ê³ " in text or "í™ë³´" in text or "ë§ˆì¼€íŒ…" in text:
        return "ê´‘ê³  ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ë¡œ ì¡ìœ¼ë©´ ì¢‹ì„ê¹Œìš”?"
    age = info.get("ê³ ê°ì—°ë ¹ëŒ€", "")
    if "30" in age or "40" in age:
        return "30~40ëŒ€ì—ê²Œ ë°˜ì‘ ì¢‹ì€ ì½˜í…ì¸  ì˜ˆì‹œë¥¼ ë” ì•Œë ¤ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?"
    if "50" in age or "60" in age:
        return "50ëŒ€ ê³ ê°ì´ ì¢‹ì•„í•  ì´ë²¤íŠ¸ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì¶”ì²œí•´ ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?"
    return "SNS í™ë³´ ì „ëµë„ ì•Œë ¤ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?"


def parse_direct_answer(answer_text: str, info: dict, question: str) -> tuple:
    """ì§ì ‘ ë‹µë³€ì—ì„œ ìƒì„¸ ê°€ì´ë“œì™€ ì¶”ì²œ ì§ˆë¬¸ì„ ë¶„ë¦¬."""
    if not answer_text:
        return "", ""

    guidance = answer_text.strip()
    suggested_question = ""
    match = re.search(r"ì¶”ì²œ\s*í›„ì†\s*ì§ˆë¬¸\s*:\s*(.+)$", guidance, flags=re.IGNORECASE | re.MULTILINE)
    if match:
        suggested_question = match.group(1).strip()
        guidance = guidance[: match.start()].strip()

    if not suggested_question:
        suggested_question = default_suggested_question(info, question)

    return guidance, suggested_question


def render_strategy_payload(payload: dict, container, prefix: str = "latest"):
    """êµ¬ì¡°í™”ëœ ì „ëµ ì‘ë‹µì„ Streamlit ì»´í¬ë„ŒíŠ¸ë¡œ ì‹œê°í™”."""
    objective = payload.get("objective")
    if objective:
        container.markdown("### ğŸ¯ Objective")
        container.markdown(objective)

    phase_titles = payload.get("phase_titles") or []
    channel_summary = payload.get("channel_summary") or []
    if channel_summary:
        container.markdown("### ğŸ“Š Recommended Channels & Phase Titles")
        summary_lines = []
        for item in channel_summary:
            channel = item.get("channel", "ì±„ë„ ë¯¸ì§€ì •")
            phase_title = item.get("phase_title", "Phase ë¯¸ì§€ì •")
            reason = item.get("reason", "")
            evidence = item.get("data_evidence", "")
            detail = f"- **{channel}** â†’ {phase_title}: {reason}"
            if evidence:
                detail += f" _(ê·¼ê±°: {evidence})_"
            summary_lines.append(detail)
        container.markdown("\n".join(summary_lines))
        if phase_titles:
            container.markdown("**Phase Titles:** " + ", ".join(phase_titles))
    elif phase_titles:
        container.markdown("### ğŸ“‹ Phase Titles")
        container.markdown(", ".join(phase_titles))

    phases = payload.get("phases") or []
    if not phases:
        return

    # Phase 1 ìš°ì„  í‘œì‹œ
    phase1 = phases[0]
    phase1_container = container.container()
    phase1_container.markdown(f"### ğŸš€ {phase1.get('title', 'Phase 1')}")
    goal = phase1.get("goal")
    if goal:
        phase1_container.markdown(f"**Goal:** {goal}")
    focus_channels = phase1.get("focus_channels") or []
    if focus_channels:
        phase1_container.markdown("**Focus Channels:** " + ", ".join(focus_channels))

    actions = phase1.get("actions") or []
    if actions:
        phase1_container.markdown("**Action Checklist:**")
        for idx, action in enumerate(actions):
            label = action.get("task", f"Action {idx + 1}")
            owner = action.get("owner")
            support = action.get("supporting_data")
            help_parts = []
            if owner:
                help_parts.append(f"ë‹´ë‹¹: {owner}")
            if support:
                help_parts.append(f"ê·¼ê±°: {support}")
            help_text = " | ".join(help_parts) if help_parts else None
            checkbox_key = f"{prefix}_phase1_action_{idx}"
            phase1_container.checkbox(label, key=checkbox_key, help=help_text)

    metrics = phase1.get("metrics") or []
    if metrics:
        phase1_container.markdown("**Metrics:**")
        phase1_container.markdown("\n".join(f"- {m}" for m in metrics))

    criteria = phase1.get("next_phase_criteria") or []
    if criteria:
        phase1_container.markdown("**Criteria To Advance:**")
        phase1_container.markdown("\n".join(f"- {c}" for c in criteria))

    evidence = phase1.get("data_evidence") or []
    if evidence:
        phase1_container.markdown("**Data Evidence:**")
        phase1_container.markdown("\n".join(f"- {e}" for e in evidence))

    suggested_question = build_phase_followup_question(phase1)
    col_followup, col_tool = phase1_container.columns([3, 2])
    followup_label = f"â“ {suggested_question}"
    followup_clicked = col_followup.button(
        followup_label,
        key=f"{prefix}_phase1_followup_btn",
        use_container_width=True,
        disabled=st.session_state.get("is_generating", False),
    )
    tool_button_clicked = col_tool.button(
        "ğŸ› ï¸ Phase 1 ë„êµ¬ ì¶”ì²œ ë³´ê¸°",
        key=f"{prefix}_phase1_tool_btn",
        use_container_width=True,
        disabled=st.session_state.get("is_generating", False),
    )

    existing_tool_info = (st.session_state.get("phase_tool_summaries") or {}).get(prefix)
    tool_placeholder = None
    if existing_tool_info:
        display_previous = (
            existing_tool_info.get("markdown")
            or existing_tool_info.get("raw")
            or ""
        )
        if display_previous:
            tool_placeholder = phase1_container.empty()
            tool_placeholder.markdown(display_previous)

    if followup_clicked and suggested_question:
        st.session_state.followup_ui = {}
        st.session_state.auto_followup_question = suggested_question
        st.rerun()

    if tool_button_clicked:
        if tool_placeholder is None:
            tool_placeholder = phase1_container.empty()
        prompt = build_phase_tool_prompt(
            payload,
            phase1 if isinstance(phase1, dict) else {},
            st.session_state.get("info", {}),
        )
        previous_generating = st.session_state.get("is_generating", False)
        st.session_state.is_generating = True
        try:
            with phase1_container:
                tool_raw = stream_gemini(
                    prompt,
                    output_placeholder=tool_placeholder,
                    status_text="Phase 1 ì‹¤í–‰ì— ë§ëŠ” ë§ˆì¼€íŒ… ë„êµ¬ë¥¼ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ› ï¸",
                    progress_text="ì „ëµê³¼ ì±„ë„ì— ë§ëŠ” íˆ´ê³¼ í™œìš©ë²•ì„ ëª¨ìœ¼ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
                    success_text="âœ… ë„êµ¬ ì¶”ì²œì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.",
                    error_status_text="ğŸš¨ ë„êµ¬ ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                )
        finally:
            st.session_state.is_generating = previous_generating

        if tool_raw:
            parsed_tool = parse_tool_suggestions(tool_raw)
            formatted_tool = format_tool_suggestions(parsed_tool)
            display_tool_text = formatted_tool or tool_raw
            tool_placeholder.markdown(display_tool_text)
            summaries = st.session_state.get("phase_tool_summaries") or {}
            summaries[prefix] = {
                "markdown": display_tool_text,
                "raw": tool_raw,
            }
            st.session_state.phase_tool_summaries = summaries
        else:
            tool_placeholder.warning("ë„êµ¬ ì¶”ì²œì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    # ë‚˜ë¨¸ì§€ PhaseëŠ” Expanderë¡œ í‘œì‹œ
    for idx, phase in enumerate(phases[1:], start=2):
        title = phase.get("title", f"Phase {idx}")
        expander = container.expander(title, expanded=False)
        goal = phase.get("goal")
        if goal:
            expander.markdown(f"**Goal:** {goal}")
        focus_channels = phase.get("focus_channels") or []
        if focus_channels:
            expander.markdown("**Focus Channels:** " + ", ".join(focus_channels))

        actions = phase.get("actions") or []
        if actions:
            expander.markdown("**Key Actions:**")
            expander.markdown("\n".join(f"- [ ] {act.get('task', 'ì‘ì—… ë¯¸ì •')}" for act in actions))

        metrics = phase.get("metrics") or []
        if metrics:
            expander.markdown("**Metrics:**")
            expander.markdown("\n".join(f"- {m}" for m in metrics))

        criteria = phase.get("next_phase_criteria") or []
        if criteria:
            expander.markdown("**Criteria To Advance:**")
            expander.markdown("\n".join(f"- {c}" for c in criteria))

        evidence = phase.get("data_evidence") or []
        if evidence:
            expander.markdown("**Data Evidence:**")
            expander.markdown("\n".join(f"- {e}" for e in evidence))

    risks = payload.get("risks") or []
    monitoring_cadence = payload.get("monitoring_cadence")
    if risks or monitoring_cadence:
        container.markdown("### âš ï¸ Risks & Monitoring")
        if risks:
            container.markdown("\n".join(f"- {r}" for r in risks))
        if monitoring_cadence:
            container.markdown(f"**Monitoring Cadence:** {monitoring_cadence}")


def render_followup_panel(guidance_text: str, evidence_list, suggested_question: str, ui_key: int):
    """Follow-up ì‘ë‹µì„ ìƒì„¸ ê°€ì´ë“œì™€ í›„ì† ì§ˆë¬¸ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ."""
    if not guidance_text:
        return

    st.markdown("### ğŸ“˜ ìƒì„¸ ê°€ì´ë“œ")
    st.markdown(guidance_text)

    evidence_items = evidence_list or []
    if evidence_items:
        st.markdown("**ê·¼ê±°:**")
        st.markdown("\n".join(f"- {item}" for item in evidence_items))

    first_time = not st.session_state.get("shown_followup_suggestion", False)
    if first_time:
        st.session_state.shown_followup_suggestion = True
        if suggested_question:
            st.markdown(f"**ê°€ëŠ¥í•œ ë‹¤ìŒ ì§ˆë¬¸:** {suggested_question}")

    col1, col2 = st.columns(2)
    suggestion_clicked = False
    if suggested_question:
        suggestion_clicked = col1.button(
            suggested_question,
            key=f"followup_suggest_{ui_key}",
            use_container_width=True,
            disabled=st.session_state.get("is_generating", False),
        )
    else:
        col1.write("")
    other_clicked = col2.button(
        "ë‹¤ë¥¸ ì§ˆë¬¸ ì…ë ¥",
        key=f"followup_new_{ui_key}",
        use_container_width=True,
        disabled=st.session_state.get("is_generating", False),
    )

    if suggestion_clicked:
        st.session_state.followup_ui = {}
        st.session_state.auto_followup_question = suggested_question
        st.rerun()

    if other_clicked:
        st.session_state.followup_ui = {}
        st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1A. ì½˜í…ì¸  ë° í”„ë¡¬í”„íŠ¸ ìƒì„± ë³´ì¡° í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COPY_LENGTH_HINTS = {
    "ì§§ê²Œ": "ë¬¸ì¥ 2~3ê°œ, 80ì ë‚´ì™¸",
    "ì¤‘ê°„": "ë¬¸ë‹¨ 2ê°œ, 120~150ì",
    "ê¸¸ê²Œ": "ë¬¸ë‹¨ 3ê°œ ì´ìƒ, 200ì ë‚´ì™¸",
}

DEFAULT_CHANNEL_OPTIONS = ["Instagram", "ë„¤ì´ë²„ ë¸”ë¡œê·¸", "ì¹´ì¹´ì˜¤í†¡ ì±„ë„", "ì˜¤í”„ë¼ì¸ POP"]
COPY_TONE_OPTIONS = ["ì¹œê·¼í•œ", "íŠ¸ë Œë””í•œ", "ì „ë¬¸ì ì¸", "ê°ì„±ì ì¸", "ë¯¿ìŒì§í•œ"]

VISUAL_STYLE_PRESETS = [
    "ë°ê³  ì¹œê·¼í•œ í‰ë©´ ì¼ëŸ¬ìŠ¤íŠ¸",
    "ì‚¬ì§„ ê°™ì€ ë¦¬ì–¼ë¦¬ì¦˜",
    "ë”°ëœ»í•œ ìˆ˜ì±„í™” í†¤",
    "ëŒ€ë¹„ ê°•í•œ í¬ìŠ¤í„° ìŠ¤íƒ€ì¼",
]
VISUAL_ASPECT_OPTIONS = ["1:1 ì •ì‚¬ê°í˜•", "3:4 ì„¸ë¡œ", "16:9 ê°€ë¡œ"]


def _strategy_context_lines(strategy_payload, max_lines: int = 8) -> list[str]:
    """ë§ˆì¼€íŒ… ì „ëµ ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ ì—ì…‹ ìƒì„± ì‹œ ì°¸ê³ í•  í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ."""
    if not strategy_payload:
        return []

    if isinstance(strategy_payload, str):
        raw_lines = [
            f"- {line.strip()}"
            for line in strategy_payload.splitlines()
            if line.strip()
        ]
        return raw_lines[:max_lines]

    if not isinstance(strategy_payload, dict):
        return []

    lines = []
    objective = strategy_payload.get("objective")
    if objective:
        lines.append(f"- Objective: {objective}")

    channel_summary = strategy_payload.get("channel_summary") or []
    for item in channel_summary[:3]:
        channel = item.get("channel", "ì±„ë„ ë¯¸ì§€ì •")
        reason = item.get("reason", "")
        evidence = item.get("data_evidence", "")
        snippet = f"- {channel}: {reason}"
        if evidence:
            snippet += f" (ê·¼ê±°: {evidence})"
        lines.append(snippet)

    phases = strategy_payload.get("phases") or []
    if phases:
        first_phase = phases[0]
        title = first_phase.get("title", "Phase 1")
        goal = first_phase.get("goal")
        if goal:
            lines.append(f"- {title} ëª©í‘œ: {goal}")
        actions = first_phase.get("actions") or []
        for action in actions[:3]:
            task = action.get("task")
            owner = action.get("owner")
            if task:
                if owner:
                    lines.append(f"- ì‹¤í–‰: {task} (ë‹´ë‹¹: {owner})")
                else:
                    lines.append(f"- ì‹¤í–‰: {task}")

    return lines[:max_lines]


def _available_channels(strategy_payload) -> list[str]:
    """ì „ëµ ë°ì´í„°ì—ì„œ ì¶”ì²œ ì±„ë„ ëª©ë¡ì„ ë½‘ì•„ ìœ ë‹ˆí¬í•˜ê²Œ ë°˜í™˜."""
    channels = []
    if isinstance(strategy_payload, dict):
        channel_summary = strategy_payload.get("channel_summary") or []
        for item in channel_summary:
            ch = item.get("channel")
            if ch:
                channels.append(ch)
        phases = strategy_payload.get("phases") or []
        for phase in phases:
            focus_channels = phase.get("focus_channels") or []
            for ch in focus_channels:
                channels.append(ch)
    unique_channels = []
    for ch in channels:
        if ch and ch not in unique_channels:
            unique_channels.append(ch)
    if not unique_channels:
        unique_channels = DEFAULT_CHANNEL_OPTIONS
    return unique_channels


def build_copy_generation_prompt(
    info: dict,
    request: dict,
    strategy_payload: dict | str | None,
) -> str:
    """ì¹´í”¼ ì´ˆì•ˆ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    store_name = info.get("ìƒì ëª…", "ìƒì ")
    industry = info.get("ì—…ì¢…", "ì†Œìƒê³µì¸")
    audience = info.get("ê³ ê°ì—°ë ¹ëŒ€", "")
    behavior = info.get("ê³ ê°í–‰ë™", "")

    tone = request.get("tone", "ì¹œê·¼í•œ")
    channel = request.get("channel", "SNS")
    length_label = request.get("length", "ì¤‘ê°„")
    length_hint = COPY_LENGTH_HINTS.get(length_label, "ë¬¸ë‹¨ 2ê°œ, 120~150ì")
    offer = request.get("offer") or "ê¸°ë³¸ ì„œë¹„ìŠ¤ì™€ ê°•ì ì„ ê°•ì¡°"
    extras = request.get("extras", "")

    strategy_lines = _strategy_context_lines(strategy_payload)
    strategy_block = "\n".join(strategy_lines) if strategy_lines else "â€¢ ì „ëµ ìš”ì•½ ì—†ìŒ"

    prompt = (
        "ë‹¹ì‹ ì€ í•œêµ­ ì¤‘ì†Œìƒê³µì¸ì˜ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ ìƒì  ì •ë³´ì™€ ì „ëµ ìš”ì•½ì„ ì°¸ê³ í•´ ë§ˆì¼€íŒ… ì¹´í”¼ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.\n"
        "ì¹´í”¼ëŠ” ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ì™„ì„±ë„ ë†’ì€ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•˜ê³ , ë¬¸ë‹¨ë§ˆë‹¤ ì´ëª¨ì§€ëŠ” ë„£ì§€ ë§ˆì„¸ìš”.\n"
        "í•µì‹¬ CTA ë¬¸ì¥ì„ í¬í•¨í•˜ê³ , ìˆ«ìë‚˜ êµ¬ì²´ì ì¸ í˜œíƒì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì£¼ì„¸ìš”.\n\n"
        f"=== ìƒì  ì •ë³´ ===\n"
        f"- ìƒí˜¸: {store_name}\n"
        f"- ì—…ì¢…: {industry}\n"
        f"- ì£¼ìš” ê³ ê°: {audience or 'ë¯¸ìƒ'} / {behavior or 'íŠ¹ì´ í–‰ë™ ë¯¸ìƒ'}\n\n"
        f"=== ì½˜í…ì¸  ìš”êµ¬ì‚¬í•­ ===\n"
        f"- ì±„ë„: {channel}\n"
        f"- í†¤ì•¤ë§¤ë„ˆ: {tone}\n"
        f"- ë¶„ëŸ‰: {length_label} ({length_hint})\n"
        f"- ê°•ì¡° í¬ì¸íŠ¸: {offer}\n"
        f"- ì¶”ê°€ ìš”ì²­: {extras or 'ì—†ìŒ'}\n\n"
        f"=== ì „ëµ ìš”ì•½ ===\n"
        f"{strategy_block}\n\n"
        "ì‘ë‹µ í˜•ì‹ ì§€ì¹¨:\n"
        "1. ì•„ë˜ì™€ ê°™ì€ ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
        "### í—¤ë“œë¼ì¸\n"
        "- í•œ ì¤„ í—¤ë“œë¼ì¸\n\n"
        "### ë³¸ë¬¸\n"
        "- ë¬¸ë‹¨ 1\n"
        "- ë¬¸ë‹¨ 2 (í•„ìš” ì‹œ)\n\n"
        "### CTA\n"
        "- í–‰ë™ì„ ìœ ë„í•˜ëŠ” í•œ ë¬¸ì¥\n\n"
        "### ì±„ë„ ì°¸ê³  ë©”ëª¨\n"
        "- ì±„ë„ ìš´ì˜ íŒ ë˜ëŠ” ê²Œì‹œ ì‹œ ì£¼ì˜ì‚¬í•­ 1~2ê°œ\n"
    )
    return prompt


def build_visual_brief_prompt(
    info: dict,
    request: dict,
    strategy_payload: dict | str | None,
) -> str:
    """ì´ë¯¸ì§€/ì¼ëŸ¬ìŠ¤íŠ¸ ì½˜ì…‰íŠ¸ ë¸Œë¦¬í”„ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    store_name = info.get("ìƒì ëª…", "ìƒì ")
    industry = info.get("ì—…ì¢…", "ì†Œìƒê³µì¸")

    focus = request.get("focus", "ëŒ€í‘œ ë©”ë‰´ì™€ ë§¤ì¥ ë¶„ìœ„ê¸°")
    style = request.get("style") or VISUAL_STYLE_PRESETS[0]
    aspect = request.get("aspect", "1:1 ì •ì‚¬ê°í˜•")
    extras = request.get("extras", "")

    strategy_lines = _strategy_context_lines(strategy_payload)
    strategy_block = "\n".join(strategy_lines) if strategy_lines else "â€¢ ì „ëµ ìš”ì•½ ì—†ìŒ"

    prompt = (
        "ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì•„íŠ¸ ë””ë ‰í„°ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•´ AI ì´ë¯¸ì§€ ìƒì„± ë„êµ¬ì— ì „ë‹¬í•  ì‹œê° ì½˜ì…‰íŠ¸ ë¸Œë¦¬í”„ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
        "ë¸Œë¦¬í”„ëŠ” ì¥ë©´ êµ¬ì„±, í•µì‹¬ ì˜¤ë¸Œì íŠ¸, ìƒ‰ê°, í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê°€ì´ë“œ ë“±ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        f"=== ìƒì  ì •ë³´ ===\n"
        f"- ìƒí˜¸: {store_name}\n"
        f"- ì—…ì¢…: {industry}\n\n"
        f"=== ìš”ì²­ ì‚¬í•­ ===\n"
        f"- ê°•ì¡° í¬ì»¤ìŠ¤: {focus}\n"
        f"- í¬ë§ ìŠ¤íƒ€ì¼: {style}\n"
        f"- ì´ë¯¸ì§€ ë¹„ìœ¨: {aspect}\n"
        f"- ì¶”ê°€ ìš”ì²­: {extras or 'ì—†ìŒ'}\n\n"
        f"=== ì „ëµ ìš”ì•½ ===\n"
        f"{strategy_block}\n\n"
        "ì‘ë‹µ í˜•ì‹ ì§€ì¹¨:\n"
        "1. ì•„ë˜ ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ ì œëª©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
        "### ì½˜ì…‰íŠ¸ ìš”ì•½\n"
        "- ì¥ë©´ í•œ ì¤„ ìš”ì•½\n\n"
        "### ì¥ë©´ êµ¬ì„±\n"
        "- ì „ê²½ ìš”ì†Œ\n"
        "- ì¤‘ê²½ ìš”ì†Œ\n"
        "- ë°°ê²½ ìš”ì†Œ\n\n"
        "### ì‹œê° í†¤ & ìŠ¤íƒ€ì¼\n"
        "- ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ 2~3ê°œ\n"
        "- ì¡°ëª…/ì§ˆê° ì„¤ëª…\n\n"
        "### í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´\n"
        "- í¬í•¨í•  ë¬¸êµ¬ 1~2ê°œ (ìˆë‹¤ë©´)\n\n"
        "### ìƒì„± íŒ\n"
        "- ì´ë¯¸ì§€ ìƒì„± ì‹œ ì£¼ì˜í•˜ê±°ë‚˜ ê°•ì¡°í•  ì‚¬í•­ 2ê°œ ë‚´ì™¸\n"
    )
    return prompt


PROMPT_EXAMPLE_GUIDE = (
    "\n\nì‘ë‹µ í˜•ì‹ ì§€ì¹¨(ì¤‘ìš”):\n"
    "{\n"
    '  "prompts": [\n'
    "    {\n"
    '      "title": "ìƒí™© ì œëª©",\n'
    '      "prompt": "AI ë„êµ¬ì— ë¶™ì—¬ë„£ì„ í”„ë¡¬í”„íŠ¸",\n'
    '      "when": "ì´ í”„ë¡¬í”„íŠ¸ê°€ ìœ ìš©í•œ ìƒí™© ì„¤ëª…"\n'
    "    }\n"
    "  ],\n"
    '  "tips": ["í™œìš© íŒ 1", "í™œìš© íŒ 2"]\n'
    "}\n"
    "í”„ë¡¬í”„íŠ¸ ë¬¸ì¥ì€ í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , í•œêµ­ì–´ ì‚¬ìš©ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ë˜ í•„ìš” ì‹œ ì˜ì–´ í‚¤ì›Œë“œë„ ë³‘ê¸°í•˜ì„¸ìš”."
)


def build_prompt_example_prompt(
    asset_type: str,
    request: dict,
    generated_asset: str,
    info: dict,
) -> str:
    """ì—ì…‹ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í›„ì† í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸."""
    asset_label = "ì¹´í”¼" if asset_type == "copy" else "ì´ë¯¸ì§€"
    context_lines = []
    if request.get("channel"):
        context_lines.append(f"- ì±„ë„: {request['channel']}")
    if request.get("tone"):
        context_lines.append(f"- í†¤: {request['tone']}")
    if request.get("length"):
        context_lines.append(f"- ë¶„ëŸ‰: {request['length']}")
    if request.get("style"):
        context_lines.append(f"- ìŠ¤íƒ€ì¼: {request['style']}")
    if request.get("focus"):
        context_lines.append(f"- ê°•ì¡° í¬ì»¤ìŠ¤: {request['focus']}")

    context_block = "\n".join(context_lines) if context_lines else "- ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ"
    store_name = info.get("ìƒì ëª…", "ìƒì ")

    prompt = (
        "ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
        f"ì´ë¯¸ ìƒì„±ëœ {asset_label} ì´ˆì•ˆì„ ê¸°ë°˜ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ë‹¤ìŒ ë°˜ë³µì—ì„œ í™œìš©í•  í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œë¥¼ ì œì•ˆí•˜ì„¸ìš”.\n"
        "í”„ë¡¬í”„íŠ¸ëŠ” ì‹¤ë¬´ìê°€ AI ë„êµ¬ì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ì„ ìˆ˜ ìˆì„ ì •ë„ë¡œ êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
        "ê° í”„ë¡¬í”„íŠ¸ëŠ” í†¤ì´ë‚˜ ëª©ì ì´ ì„œë¡œ ë‹¤ë¥´ê²Œ êµ¬ì„±í•´ ì„ íƒì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n"
        f"=== ìƒì ëª… ===\n- {store_name}\n\n"
        f"=== ì»¨í…ìŠ¤íŠ¸ ===\n{context_block}\n\n"
        f"=== í˜„ì¬ ì´ˆì•ˆ ===\n{generated_asset.strip()}\n"
        f"{PROMPT_EXAMPLE_GUIDE}"
    )
    return prompt


def parse_prompt_examples(raw_text: str) -> dict:
    """í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ JSONì„ íŒŒì‹±í•˜ê³ , ì‹¤íŒ¨ ì‹œ ì›ë¬¸ì„ í•¨ê»˜ ë°˜í™˜."""
    candidate = strip_json_artifacts(raw_text)
    if not candidate:
        return {"prompts": [], "tips": [], "raw": raw_text.strip()}

    try:
        data = json.loads(candidate)
    except json.JSONDecodeError:
        return {"prompts": [], "tips": [], "raw": raw_text.strip()}

    prompts = data.get("prompts") if isinstance(data, dict) else None
    tips = data.get("tips") if isinstance(data, dict) else None

    if not isinstance(prompts, list):
        prompts = []
    normalized_prompts = []
    for item in prompts:
        if not isinstance(item, dict):
            continue
        title = item.get("title") or item.get("name") or ""
        prompt_text = item.get("prompt") or item.get("content") or ""
        when = item.get("when") or item.get("best_for") or ""
        if prompt_text:
            normalized_prompts.append(
                {
                    "title": title.strip() if isinstance(title, str) else "",
                    "prompt": prompt_text.strip() if isinstance(prompt_text, str) else "",
                    "when": when.strip() if isinstance(when, str) else "",
                }
            )

    if not isinstance(tips, list):
        tips = []
    normalized_tips = [
        tip.strip() for tip in tips if isinstance(tip, str) and tip.strip()
    ]

    return {
        "prompts": normalized_prompts,
        "tips": normalized_tips,
        "raw": candidate.strip(),
    }


def render_copy_workspace(info: dict, strategy_payload, raw_strategy: str | None):
    """ì¹´í”¼ ìƒì„± ë° í”„ë¡¬í”„íŠ¸ ì¶”ì²œ UI."""
    st.markdown("#### ğŸ“ ë§ˆì¼€íŒ… ì¹´í”¼")
    st.caption("ì±„ë„ë³„ ì¹´í”¼ ì´ˆì•ˆì„ ë¨¼ì € ìƒì„±í•˜ê³ , ì´ì–´ì„œ ë³€í˜•ì— ì“¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ì²œë°›ìœ¼ì„¸ìš”.")

    available_channels = _available_channels(strategy_payload if strategy_payload else raw_strategy)
    prev_context = st.session_state.copy_context or {}

    default_channel = prev_context.get("channel", available_channels[0] if available_channels else "SNS")
    channel_index = available_channels.index(default_channel) if default_channel in available_channels else 0
    channel = st.selectbox(
        "ì±„ë„ ì„ íƒ",
        available_channels,
        index=channel_index if available_channels else 0,
        key="copy_channel_select",
    )

    tone_default = prev_context.get("tone", COPY_TONE_OPTIONS[0])
    tone_index = COPY_TONE_OPTIONS.index(tone_default) if tone_default in COPY_TONE_OPTIONS else 0
    tone = st.selectbox("í†¤ì•¤ë§¤ë„ˆ", COPY_TONE_OPTIONS, index=tone_index, key="copy_tone_select")

    length_options = list(COPY_LENGTH_HINTS.keys())
    length_default = prev_context.get("length", "ì¤‘ê°„")
    length_index = length_options.index(length_default) if length_default in length_options else 1
    length = st.radio("ë¶„ëŸ‰", length_options, index=length_index, horizontal=True, key="copy_length_radio")

    offer = st.text_input(
        "ê°•ì¡°í•  í˜œíƒ/í”„ë¡œëª¨ì…˜",
        value=prev_context.get("offer", ""),
        placeholder="ì˜ˆ: 11ì›” í•œì • ì‹ ë©”ë‰´ 10% í• ì¸, ì˜¤ì „ 11ì‹œê¹Œì§€ ì•„ë©”ë¦¬ì¹´ë…¸ 1+1",
        key="copy_offer_input",
    )
    extras = st.text_area(
        "ì¶”ê°€ ìš”ì²­ (ì„ íƒ)",
        value=prev_context.get("extras", ""),
        placeholder="ì˜ˆ: ì²« ë¬¸ì¥ì€ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘, í•´ì‹œíƒœê·¸ 3ê°œ í¬í•¨, ìˆ«ì ë°ì´í„° ê°•ì¡°",
        height=80,
        key="copy_extra_input",
    )

    col_generate, col_clear = st.columns([3, 1])
    with col_generate:
        disable_generate = (
            st.session_state.copy_generation_in_progress
            or st.session_state.visual_generation_in_progress
            or st.session_state.get("is_generating", False)
        )
        if st.button(
            "AI ì¹´í”¼ ì´ˆì•ˆ ìƒì„±",
            key="copy_generate_button",
            use_container_width=True,
            disabled=disable_generate,
        ):
            request_payload = {
                "channel": channel,
                "tone": tone,
                "length": length,
                "offer": offer.strip(),
                "extras": extras.strip(),
            }
            st.session_state.copy_context = request_payload
            st.session_state.copy_request = request_payload
            st.session_state.copy_generation_in_progress = True
            st.session_state.copy_draft = ""
            st.session_state.copy_prompt_examples = []
            st.session_state.copy_prompt_tips = []
            st.session_state.copy_prompts_raw = ""
            st.rerun()

    with col_clear:
        if st.button(
            "ì´ˆì•ˆ ì´ˆê¸°í™”",
            key="copy_clear_button",
            use_container_width=True,
            disabled=st.session_state.copy_generation_in_progress,
        ):
            st.session_state.copy_draft = ""
            st.session_state.copy_prompt_examples = []
            st.session_state.copy_prompt_tips = []
            st.session_state.copy_prompts_raw = ""
            st.rerun()

    if st.session_state.copy_generation_in_progress and st.session_state.copy_request:
        generation_container = st.container()
        with generation_container:
            placeholder = st.empty()
            prompt = build_copy_generation_prompt(
                info,
                st.session_state.copy_request,
                strategy_payload or raw_strategy,
            )
            copy_result = stream_gemini(
                prompt,
                output_placeholder=placeholder,
                status_text="ì¹´í”¼ ì´ˆì•ˆì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... âœï¸",
                progress_text="ì „ëµê³¼ ìš”ì²­ì„ ë°˜ì˜í•´ ë¬¸êµ¬ë¥¼ ë‹¤ë“¬ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
                success_text="âœ… ì¹´í”¼ ì´ˆì•ˆì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                error_status_text="ğŸš¨ ì¹´í”¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            )

        st.session_state.copy_generation_in_progress = False
        st.session_state.copy_request = None

        if copy_result:
            st.session_state.copy_draft = copy_result.strip()
            prompt_container = st.container()
            with prompt_container:
                prompt_placeholder = st.empty()
                prompt_request = build_prompt_example_prompt(
                    "copy",
                    st.session_state.copy_context,
                    st.session_state.copy_draft,
                    info,
                )
                prompt_result = stream_gemini(
                    prompt_request,
                    output_placeholder=prompt_placeholder,
                    status_text="ì¶”ì²œ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ’¡",
                    progress_text="ë‹¤ìŒ ë°˜ë³µì— ì“¸ í”„ë¡¬í”„íŠ¸ ë³€í˜•ì„ ëª¨ìœ¼ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
                    success_text="âœ… í”„ë¡¬í”„íŠ¸ ì œì•ˆì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    error_status_text="ğŸš¨ í”„ë¡¬í”„íŠ¸ ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                )
            if prompt_result:
                parsed = parse_prompt_examples(prompt_result)
                st.session_state.copy_prompt_examples = parsed.get("prompts", [])
                st.session_state.copy_prompt_tips = parsed.get("tips", [])
                st.session_state.copy_prompts_raw = parsed.get("raw", "")
            else:
                st.session_state.copy_prompt_examples = []
                st.session_state.copy_prompt_tips = []
                st.session_state.copy_prompts_raw = ""
        else:
            st.session_state.copy_draft = ""
            st.session_state.copy_prompt_examples = []
            st.session_state.copy_prompt_tips = []
            st.session_state.copy_prompts_raw = ""

        st.rerun()

    if st.session_state.copy_draft:
        st.markdown("##### ìƒì„±ëœ ì¹´í”¼")
        st.markdown(st.session_state.copy_draft)

        with st.expander("ğŸ”§ í”„ë¡¬í”„íŠ¸ ì¶”ì²œ", expanded=False):
            if st.session_state.copy_prompt_examples:
                for idx, item in enumerate(st.session_state.copy_prompt_examples, start=1):
                    title = item.get("title") or f"í”„ë¡¬í”„íŠ¸ {idx}"
                    prompt_text = item.get("prompt", "")
                    when_text = item.get("when", "")
                    st.markdown(f"**{title}**")
                    if prompt_text:
                        st.code(prompt_text, language="text")
                    if when_text:
                        st.caption(when_text)
            elif st.session_state.copy_prompts_raw:
                st.markdown(st.session_state.copy_prompts_raw)

            if st.session_state.copy_prompt_tips:
                st.markdown("**í™œìš© íŒ**")
                tips_markdown = "\n".join(f"- {tip}" for tip in st.session_state.copy_prompt_tips)
                st.markdown(tips_markdown)
    else:
        st.info("ìƒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ ì±„ë„ì— ë§ëŠ” ì¹´í”¼ ì´ˆì•ˆì„ ë°›ì•„ë³´ì„¸ìš”.")


def render_visual_workspace(info: dict, strategy_payload, raw_strategy: str | None):
    """ë¹„ì£¼ì–¼ ë¸Œë¦¬í”„ ìƒì„± ë° í”„ë¡¬í”„íŠ¸ ì¶”ì²œ UI."""
    st.markdown("#### ğŸ¨ ì´ë¯¸ì§€/ì¼ëŸ¬ìŠ¤íŠ¸ ë¸Œë¦¬í”„")
    st.caption("AIê°€ ë¨¼ì € ì½˜ì…‰íŠ¸ ë¸Œë¦¬í”„ë¥¼ ì œì•ˆí•˜ê³ , ì´ì–´ì„œ ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")

    prev_context = st.session_state.visual_context or {}

    focus = st.text_input(
        "ê°•ì¡° í¬ì»¤ìŠ¤",
        value=prev_context.get("focus", "ëŒ€í‘œ ìƒí’ˆê³¼ ë§¤ì¥ ë¶„ìœ„ê¸°"),
        placeholder="ì˜ˆ: ê²¨ìš¸ í•œì • ë©”ë‰´, ë°°ë‹¬ ì„œë¹„ìŠ¤, í…Œì´í¬ì•„ì›ƒ ì¡´",
        key="visual_focus_input",
    )

    style_default = prev_context.get("style", VISUAL_STYLE_PRESETS[0])
    style_index = VISUAL_STYLE_PRESETS.index(style_default) if style_default in VISUAL_STYLE_PRESETS else 0
    style = st.selectbox(
        "í¬ë§ ìŠ¤íƒ€ì¼",
        VISUAL_STYLE_PRESETS,
        index=style_index,
        key="visual_style_select",
    )

    aspect_default = prev_context.get("aspect", VISUAL_ASPECT_OPTIONS[0])
    aspect_index = VISUAL_ASPECT_OPTIONS.index(aspect_default) if aspect_default in VISUAL_ASPECT_OPTIONS else 0
    aspect = st.selectbox(
        "ì´ë¯¸ì§€ ë¹„ìœ¨",
        VISUAL_ASPECT_OPTIONS,
        index=aspect_index,
        key="visual_aspect_select",
    )

    extras = st.text_area(
        "ì¶”ê°€ ìš”ì²­ (ì„ íƒ)",
        value=prev_context.get("extras", ""),
        placeholder="ì˜ˆ: ë”°ëœ»í•œ ì¡°ëª…ê°, ë§¤ì¥ ì™¸ë¶€ ì „ê²½ í¬í•¨, í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë§Œ ì‚¬ìš©",
        height=80,
        key="visual_extra_input",
    )

    col_generate, col_clear = st.columns([3, 1])
    with col_generate:
        disable_generate = (
            st.session_state.visual_generation_in_progress
            or st.session_state.copy_generation_in_progress
            or st.session_state.get("is_generating", False)
        )
        if st.button(
            "AI ë¸Œë¦¬í”„ ìƒì„±",
            key="visual_generate_button",
            use_container_width=True,
            disabled=disable_generate,
        ):
            request_payload = {
                "focus": focus.strip(),
                "style": style,
                "aspect": aspect,
                "extras": extras.strip(),
            }
            st.session_state.visual_context = request_payload
            st.session_state.visual_request = request_payload
            st.session_state.visual_generation_in_progress = True
            st.session_state.visual_brief = ""
            st.session_state.visual_prompt_examples = []
            st.session_state.visual_prompt_tips = []
            st.session_state.visual_prompts_raw = ""
            st.rerun()

    with col_clear:
        if st.button(
            "ë¸Œë¦¬í”„ ì´ˆê¸°í™”",
            key="visual_clear_button",
            use_container_width=True,
            disabled=st.session_state.visual_generation_in_progress,
        ):
            st.session_state.visual_brief = ""
            st.session_state.visual_prompt_examples = []
            st.session_state.visual_prompt_tips = []
            st.session_state.visual_prompts_raw = ""
            st.rerun()

    if st.session_state.visual_generation_in_progress and st.session_state.visual_request:
        generation_container = st.container()
        with generation_container:
            placeholder = st.empty()
            prompt = build_visual_brief_prompt(
                info,
                st.session_state.visual_request,
                strategy_payload or raw_strategy,
            )
            brief_result = stream_gemini(
                prompt,
                output_placeholder=placeholder,
                status_text="ì´ë¯¸ì§€ ì½˜ì…‰íŠ¸ë¥¼ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ¨",
                progress_text="ìš”ì²­í•œ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•´ ì¥ë©´ì„ êµ¬ì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
                success_text="âœ… ë¸Œë¦¬í”„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                error_status_text="ğŸš¨ ë¸Œë¦¬í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            )

        st.session_state.visual_generation_in_progress = False
        st.session_state.visual_request = None

        if brief_result:
            st.session_state.visual_brief = brief_result.strip()
            prompt_container = st.container()
            with prompt_container:
                prompt_placeholder = st.empty()
                prompt_request = build_prompt_example_prompt(
                    "visual",
                    st.session_state.visual_context,
                    st.session_state.visual_brief,
                    info,
                )
                prompt_result = stream_gemini(
                    prompt_request,
                    output_placeholder=prompt_placeholder,
                    status_text="ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ’¡",
                    progress_text="ë‹¤ìŒ ë³€í˜•ì— ì“¸ í”„ë¡¬í”„íŠ¸ ì˜µì…˜ì„ ëª¨ìœ¼ëŠ” ì¤‘ì…ë‹ˆë‹¤...",
                    success_text="âœ… í”„ë¡¬í”„íŠ¸ ì œì•ˆì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    error_status_text="ğŸš¨ í”„ë¡¬í”„íŠ¸ ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                )

            if prompt_result:
                parsed = parse_prompt_examples(prompt_result)
                st.session_state.visual_prompt_examples = parsed.get("prompts", [])
                st.session_state.visual_prompt_tips = parsed.get("tips", [])
                st.session_state.visual_prompts_raw = parsed.get("raw", "")
            else:
                st.session_state.visual_prompt_examples = []
                st.session_state.visual_prompt_tips = []
                st.session_state.visual_prompts_raw = ""
        else:
            st.session_state.visual_brief = ""
            st.session_state.visual_prompt_examples = []
            st.session_state.visual_prompt_tips = []
            st.session_state.visual_prompts_raw = ""

        st.rerun()

    if st.session_state.visual_brief:
        st.markdown("##### ìƒì„±ëœ ë¸Œë¦¬í”„")
        st.markdown(st.session_state.visual_brief)

        with st.expander("ğŸ”§ í”„ë¡¬í”„íŠ¸ ì¶”ì²œ", expanded=False):
            if st.session_state.visual_prompt_examples:
                for idx, item in enumerate(st.session_state.visual_prompt_examples, start=1):
                    title = item.get("title") or f"í”„ë¡¬í”„íŠ¸ {idx}"
                    prompt_text = item.get("prompt", "")
                    when_text = item.get("when", "")
                    st.markdown(f"**{title}**")
                    if prompt_text:
                        st.code(prompt_text, language="text")
                    if when_text:
                        st.caption(when_text)
            elif st.session_state.visual_prompts_raw:
                st.markdown(st.session_state.visual_prompts_raw)

            if st.session_state.visual_prompt_tips:
                st.markdown("**í™œìš© íŒ**")
                tips_markdown = "\n".join(f"- {tip}" for tip in st.session_state.visual_prompt_tips)
                st.markdown(tips_markdown)
    else:
        st.info("ìƒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ ì´ë¯¸ì§€ ì œì‘ì— í™œìš©í•  ë¸Œë¦¬í”„ë¥¼ ë°›ì•„ë³´ì„¸ìš”.")


def render_asset_workshop(strategy_payload, raw_strategy: str | None, info: dict):
    """ì½˜í…ì¸ /ì´ë¯¸ì§€ ìƒì„± ì›Œí¬ìŠ¤í˜ì´ìŠ¤ë¥¼ ë Œë”ë§."""
    st.markdown("### âœ¨ ì½˜í…ì¸  & ì´ë¯¸ì§€ ìƒì„± ì›Œí¬ìŠ¤í˜ì´ìŠ¤")
    st.caption("AIê°€ ë¨¼ì € ì´ˆì•ˆì„ ì œì‹œí•˜ê³ , ì´ì–´ì„œ í™œìš©í•  í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

    copy_tab, visual_tab = st.tabs(["ì¹´í”¼ ìƒì„±", "ì´ë¯¸ì§€ ë¸Œë¦¬í”„"])
    with copy_tab:
        render_copy_workspace(info, strategy_payload, raw_strategy)
    with visual_tab:
        render_visual_workspace(info, strategy_payload, raw_strategy)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Persona ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_personas(path="personas.json"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        st.error("âš ï¸ personas.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. prompt_generator.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return []

personas = load_personas()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ì—…ì¢… ë¶„ë¥˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BRAND_KEYWORDS_BY_CATEGORY = {
    "ì¹´í˜/ë””ì €íŠ¸": {
        "íŒŒë¦¬",
        "ëšœë ˆ",
        "ë°°ìŠ¤",
        "ë² ìŠ¤",
        "ë² ìŠ¤í‚¨",
        "ë˜í‚¨",
        "í¬ë¦¬ìŠ¤í”¼",
        "íˆ¬ì¸",
        "ì´ë””",
        "ë¹½ë‹¤",
        "ë©”ê°€",
        "ë©”ë¨¸",
        "ë§¤ë¨¸",
        "ì»´í¬",
        "ì»´í¬ì¦ˆ",
        "í• ë¦¬",
        "ìŠ¤íƒ€ë²…",
        "íƒì•¤",
        "ê³µì°¨",
        "ìš”ê±°",
        "ì™€í”ŒëŒ€",
        "ì™€í”Œ",
        "í´ë°”ì…‹",
    },
    "í•œì‹": {
        "êµì´Œ",
        "ë„¤ë„¤",
        "í˜¸ì‹",
        "ë‘˜ë‘˜",
        "ì²˜ê°“",
        "êµ½ë„¤",
        "bbq",
        "bhc",
        "ë§˜ìŠ¤",
        "ë§˜ìŠ¤í„°ì¹˜",
        "ì£ ìŠ¤",
        "ì‹ ì „",
        "êµ­ëŒ€",
        "ëª…ë‘",
        "ë‘ë¼",
        "ë•…ìŠ¤",
        "ëª…ë¥œ",
        "í•˜ë‚¨",
        "ë“±ì´Œ",
        "ë´‰ì¶”",
        "ì›í• ",
        "ë³¸ì£½",
        "ì›í• ë¨¸ë‹ˆ",
        "í•œì´Œ",
        "ë°±ì±„",
        "í•œì†¥",
        "ë°”ë¥´",
    },
    "ì–‘ì‹/ì„¸ê³„ìš”ë¦¬": {
        "ë„ë¯¸",
        "í”¼ìí—›",
        "íŒŒíŒŒ",
        "íŒŒíŒŒì¡´ìŠ¤",
        "ë¡¯ë°",
        "ë²„ê±°í‚¹",
        "ì¨ë¸Œ",
        "ì„œë¸Œì›¨ì´",
        "ì´ì‚­",
        "í”„ë­",
        "í”„ë­í¬",
        "í”¼ììŠ¤ì¿¨",
    },
    "ì£¼ì /ì£¼ë¥˜": {
        "í•œì‹ ",
    },
}


def classify_hpsn_mct(name: str) -> str:
    normalized = _normalize_name(name)
    for category, keywords in BRAND_KEYWORDS_BY_CATEGORY.items():
        if any(k in normalized for k in keywords):
            return category

    nm = name.strip().lower()
    if any(k in nm for k in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë„ë„ˆì¸ ", "ë¹™ìˆ˜", "ì™€í”Œ", "ë§ˆì¹´ë¡±"]):
        return "ì¹´í˜/ë””ì €íŠ¸"
    if any(k in nm for k in ["í•œì‹", "êµ­ë°¥", "ë°±ë°˜", "ì°Œê°œ", "ê°ìíƒ•", "ë¶„ì‹", "ì¹˜í‚¨", "í•œì •ì‹", "ì£½"]):
        return "í•œì‹"
    if any(k in nm for k in ["ì¼ì‹", "ì´ˆë°¥", "ëˆê°€ìŠ¤", "ë¼ë©˜", "ë®ë°¥", "ì†Œë°”", "ì´ìì¹´ì•¼"]):
        return "ì¼ì‹"
    if any(k in nm for k in ["ì¤‘ì‹", "ì§¬ë½•", "ì§œì¥", "ë§ˆë¼", "í› ê¶ˆ", "ë”¤ì„¬"]):
        return "ì¤‘ì‹"
    if any(k in nm for k in ["ì–‘ì‹", "ìŠ¤í…Œì´í¬", "í”¼ì", "íŒŒìŠ¤íƒ€", "í–„ë²„ê±°", "ìƒŒë“œìœ„ì¹˜", "í† ìŠ¤íŠ¸", "ë²„ê±°"]):
        return "ì–‘ì‹/ì„¸ê³„ìš”ë¦¬"
    if any(k in nm for k in ["ì£¼ì ", "í˜¸í”„", "ë§¥ì£¼", "ì™€ì¸ë°”", "ì†Œì£¼", "ìš”ë¦¬ì£¼ì ", "ì´ìì¹´ì•¼"]):
        return "ì£¼ì /ì£¼ë¥˜"
    return "ê¸°íƒ€"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. í”„ëœì°¨ì´ì¦ˆ íŒë³„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BRAND_KEYWORDS = {kw for kws in BRAND_KEYWORDS_BY_CATEGORY.values() for kw in kws}

# 2) ì˜¤ê²€ì¶œì„ ì¤„ì´ê¸° ìœ„í•œ ì˜ˆì™¸/ëª¨í˜¸ í† í° (ìƒí™© ë³´ê³  ì¶”ê°€)
AMBIGUOUS_NEGATIVES = {
    # ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ì§€ì—­/ì§€ëª…/ì—…ì¢…ì„± í† í°
    "ì¹´í˜", "ì»¤í”¼", "ì™•ì‹­", "ì„±ìˆ˜", "í–‰ë‹¹", "ì¢…ë¡œ", "ì „ì£¼", "ì¶˜ì²œ", "ì™€ì¸", "ì¹˜í‚¨", "í”¼ì", "ë¶„ì‹",
    "êµ­ìˆ˜", "ì´ˆë°¥", "ìŠ¤ì‹œ", "ê³±ì°½", "ë¼ì§€", "í•œìš°", "ë§‰ì°½", "ìˆ˜ì‚°", "ì¶•ì‚°", "ë² ì´", "ë¸Œë ˆ", "ë¸Œë ˆë“œ",
}

def _normalize_name(name: str) -> str:
    """
    - ë§ˆìŠ¤í‚¹(*), ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°
    - ì†Œë¬¸ì ë³€í™˜(ì˜ë¬¸ ëŒ€ë¹„)
    """
    n = name.lower()
    n = re.sub(r"[\s\*\-\(\)\[\]{}_/\\.|,!?&^%$#@~`+=:;\"']", "", n)
    return n

def is_franchise(name: str) -> bool:
    """
    ë°ì´í„°ì…‹2ì˜ 'ìƒí˜¸ëª…' ë¬¸ìì—´ë§Œìœ¼ë¡œ í”„ëœì°¨ì´ì¦ˆ ì—¬ë¶€ë¥¼ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ íŒì •.
    - 1ì°¨: ë¸Œëœë“œ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    - 2ì°¨: ëª¨í˜¸/ì¼ë°˜ í† í°ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê²½ìš° ì œì™¸
    - 3ì°¨(ì„ íƒ): 'ì ' íŒ¨í„´(ì§€ì ëª…) ë³´ì •
    """
    n = _normalize_name(name)
    if not n:
        return False
    has_branch_marker = "ì " in name
    hit = any(k in n for k in BRAND_KEYWORDS)
    if hit:
        if any(bad in n for bad in AMBIGUOUS_NEGATIVES):
            short_hits = [k for k in BRAND_KEYWORDS if k in n and len(k) <= 2]
            if short_hits and not has_branch_marker:
                return False
        return True
    return False


def _store_age_label_from_months(months: int) -> str:
    if months <= 12:
        return "ì‹ ê·œ"
    if months <= 24:
        return "ì „í™˜ê¸°"
    return "ì˜¤ë˜ëœ"


def extract_initial_store_info(text: str) -> tuple:
    """ë³µí•© ë¬¸ì¥ì—ì„œ ìƒì  ì •ë³´ì™€ ì§ˆë¬¸ì„ ë¶„ë¦¬í•´ ì¶”ì¶œ."""
    info_updates = {}
    question = None
    if not text:
        return info_updates, question

    sentences = re.split(r"(?<=[?.!])\s+", text.strip())
    info_sentences = []
    question_sentences = []

    for sentence in sentences:
        stripped = sentence.strip()
        if not stripped:
            continue
        if "?" in stripped or stripped.endswith("ê¹Œìš”") or stripped.endswith("í•  ìˆ˜ ìˆì„ê¹Œìš”") or "ì–´ë–»ê²Œ" in stripped:
            question_sentences.append(stripped)
        else:
            info_sentences.append(stripped)

    if not question_sentences and info_sentences:
        # ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼
        question_sentences.append(info_sentences.pop())

    context_text = " ".join(info_sentences) if info_sentences else text.strip()
    question = " ".join(question_sentences).strip() if question_sentences else text.strip()

    normalized_no_space = _normalize_name(context_text)
    brand_hits = [kw for kw in BRAND_KEYWORDS if kw in normalized_no_space]
    if brand_hits:
        store_name = max(brand_hits, key=len)
        info_updates["ìƒì ëª…"] = store_name
    else:
        name_match = re.search(r"([ê°€-í£A-Za-z0-9]+)(?:ì )?(?:ì…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”|ì—ìš”)", context_text)
        if name_match:
            info_updates["ìƒì ëª…"] = name_match.group(1)

    age_months = None
    year_match = re.search(r"(\d+)\s*(?:ë…„|ë…„ì°¨|ë…„ì§¸)", text)
    month_match = re.search(r"(\d+)\s*(?:ê°œì›”|ë‹¬)", text)
    if year_match:
        age_months = int(year_match.group(1)) * 12
    elif month_match:
        age_months = int(month_match.group(1))

    if age_months is not None:
        info_updates["ì í¬ì—°ë ¹"] = _store_age_label_from_months(age_months)

    if re.search(r"20\s*ëŒ€", text):
        info_updates["ê³ ê°ì—°ë ¹ëŒ€"] = "20ëŒ€ ì´í•˜ ê³ ê° ì¤‘ì‹¬"
    elif re.search(r"(?:30|40)\s*ëŒ€", text):
        info_updates["ê³ ê°ì—°ë ¹ëŒ€"] = "30~40ëŒ€ ê³ ê° ì¤‘ì‹¬"
    elif re.search(r"(?:50|60)\s*ëŒ€", text):
        info_updates["ê³ ê°ì—°ë ¹ëŒ€"] = "50ëŒ€ ì´ìƒ ê³ ê° ì¤‘ì‹¬"

    behaviors = []
    if "ë‹¨ê³¨" in text or "ì¬ë°©ë¬¸" in text:
        behaviors.append("ì¬ë°©ë¬¸ ê³ ê°")
    if "ì‹ ê·œ" in text or "ìƒˆì†ë‹˜" in text or "ìƒˆ ì†ë‹˜" in text:
        behaviors.append("ì‹ ê·œ ê³ ê°")
    if "ê±°ì£¼" in text or "ì£¼ë¯¼" in text:
        behaviors.append("ê±°ì£¼ ê³ ê°")
    if "ì§ì¥" in text or "ì˜¤í”¼ìŠ¤" in text or "íšŒì‚¬" in text:
        behaviors.append("ì§ì¥ì¸ ê³ ê°")
    if "ìœ ë™" in text or "ì§€ë‚˜ê°€ëŠ”" in text or "ê´€ê´‘" in text:
        behaviors.append("ìœ ë™ ê³ ê°")

    if behaviors:
        info_updates["ê³ ê°í–‰ë™"] = " + ".join(sorted(set(behaviors)))

    return info_updates, question


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Gemini Streaming í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_MODEL = "gemini-2.5-flash"

# https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash
def stream_gemini(
    prompt,
    model=DEFAULT_MODEL,
    temperature=0.6,
    max_tokens=65535,
    output_placeholder=None,
    status_text="ì „ëµì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤... â³",
    progress_text="AIê°€ ì „ëµì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ“‹",
    success_text="âœ… ì „ëµ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
    error_status_text="ğŸš¨ ì „ëµ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
):
    """ì•ˆì •ì ì¸ ìŠ¤íŠ¸ë¦¬ë° + ì™„ë£Œì‚¬ìœ  ì ê²€ + ì¹œì ˆí•œ ì—ëŸ¬"""
    status_placeholder = st.empty()
    status_placeholder.info(status_text)
    step_interval = 2.0
    step_state = {"idx": 0, "next_time": time.time() + step_interval}

    try:
        gmodel = genai.GenerativeModel(model)
        cfg = {
            "temperature": temperature,
            "max_output_tokens": max_tokens,
            "top_p": 0.9,
            "top_k": 40,
        }

        stream = gmodel.generate_content(prompt, generation_config=cfg, stream=True)

        placeholder = output_placeholder or st.empty()
        placeholder.info(progress_text)
        full_text = ""

        # 1) ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì§‘ (chunk.textê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ candidatesë„ í™•ì¸)
        for event in stream:
            piece = ""
            if getattr(event, "text", None):
                piece = event.text
            elif getattr(event, "candidates", None):
                # ì¼ë¶€ ì´ë²¤íŠ¸ëŠ” delta í˜•íƒœë¡œ ë“¤ì–´ì™€ì„œ textê°€ ë¹„ì–´ ìˆìŒ
                for c in event.candidates:
                    # ê° candidateì˜ contentì—ì„œ ì¶”ê°€ í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
                    try:
                        piece += "".join([p.text or "" for p in c.content.parts])
                    except Exception:
                        pass

            if piece:
                full_text += piece

        # 2) ìµœì¢… í•´ì„ (finish_reason/blocked ì—¬ë¶€ í™•ì¸)
        try:
            stream.resolve()  # ìµœì¢… ìƒíƒœ/ë©”íƒ€ í™•ë³´
        except Exception:
            # resolveì—ì„œ ì˜¤ë¥˜ê°€ ë‚˜ë„ ë³¸ë¬¸ì´ ìˆìœ¼ë©´ ê³„ì† ì§„í–‰
            pass

        if not full_text:
            placeholder.warning("ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

        # finish_reason/blocked ì•ˆë‚´
        try:
            cand0 = stream.candidates[0]
            fr = getattr(cand0, "finish_reason", None)
            block = getattr(cand0, "safety_ratings", None)
        except Exception:
            fr, block = None, None

        # 3) ì˜ë¦¼/ì°¨ë‹¨ ì•ˆë‚´ + ì´ì–´ì“°ê¸° ë²„íŠ¼
        if fr == "MAX_TOKENS":
            st.info("â„¹ï¸ ì‘ë‹µì´ ê¸¸ì–´ ì¤‘ê°„ì— ì˜ë ¸ì–´ìš”. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ì´ì–´ì„œ ìƒì„±í•  ìˆ˜ ìˆì–´ìš”.")
            if st.button("â• ì´ì–´ì„œ ë” ìƒì„±"):
                continue_from(full_text, prompt, gmodel, cfg)
        elif fr == "SAFETY":
            st.warning("âš ï¸ ì•ˆì „ í•„í„°ë¡œ ì¼ë¶€ ë‚´ìš©ì´ ìˆ¨ê²¨ì¡Œì„ ìˆ˜ ìˆì–´ìš”. í‘œí˜„ì„ ë‹¤ë“¬ì–´ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

        status_placeholder.success(success_text)
        return full_text

    except Exception as e:
        status_placeholder.error(error_status_text)
        st.error(
            "ğŸš¨ Gemini ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
            f"**ì—ëŸ¬ ìœ í˜•**: {type(e).__name__}\n"
            f"**ë©”ì‹œì§€**: {e}\n\n"
            "â€¢ API Key/ëª¨ë¸ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.\n"
            "â€¢ ì¼ì‹œì ì¸ ë„¤íŠ¸ì›Œí¬/ì„œë¹„ìŠ¤ ì´ìŠˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        )
        return None


def continue_from(previous_text: str, original_prompt: str, gmodel, cfg):
    """
    MAX_TOKENSë¡œ ì˜ë ¸ì„ ë•Œ ì´ì–´ì“°ê¸°. ì›ë³¸ ë¬¸ë§¥ì„ ê°„ë‹¨íˆ ìš”ì•½Â·ë³µì›í•´ ì—°ì†ì„± ìœ ì§€.
    """
    followup_prompt = (
        "ì•„ë˜ ì´ˆì•ˆì˜ ì´ì–´ì§€ëŠ” ë‚´ìš©ì„ ê°™ì€ í†¤/ì„œì‹ìœ¼ë¡œ ê³„ì† ì‘ì„±í•˜ì„¸ìš”. "
        "ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì—†ì´ Phase ë‚˜ë¨¸ì§€ì™€ KPI, ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§ˆì € ì±„ì›Œì£¼ì„¸ìš”.\n\n"
        "=== ì§€ê¸ˆê¹Œì§€ ìƒì„±ëœ ì´ˆì•ˆ ===\n"
        f"{previous_text}\n"
        "=== ì›ë˜ì˜ ìš”êµ¬ì‚¬í•­ ===\n"
        f"{original_prompt}\n"
    )

    try:
        stream2 = gmodel.generate_content(followup_prompt, generation_config=cfg, stream=True)
        placeholder = st.empty()
        full2 = ""
        for ev in stream2:
            if getattr(ev, "text", None):
                full2 += ev.text
                placeholder.markdown(full2 + "â–Œ")
        placeholder.markdown(full2)
        st.session_state.chat_history.append({"role": "assistant", "content": full2})
    except Exception as e:
        st.error(
            "ğŸš¨ ì´ì–´ì“°ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
            f"**ì—ëŸ¬ ìœ í˜•**: {type(e).__name__}\n"
            f"**ë©”ì‹œì§€**: {e}"
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. í˜ë¥´ì†Œë‚˜ ë§¤ì¹­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_persona(ì—…ì¢…, í”„ëœì°¨ì´ì¦ˆ, ì í¬ì—°ë ¹="ë¯¸ìƒ", ê³ ê°ì—°ë ¹ëŒ€="ë¯¸ìƒ", ê³ ê°í–‰ë™="ë¯¸ìƒ"):
    for p in personas:
        if p["ì—…ì¢…"] == ì—…ì¢… and p["í”„ëœì°¨ì´ì¦ˆì—¬ë¶€"] == í”„ëœì°¨ì´ì¦ˆ:
            return p
    return None  # None ê·¸ëŒ€ë¡œ ë°˜í™˜

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. Streamlit UI ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="AI ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸", layout="wide")
st.title("ğŸ’¬ AI ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸")

if st.button("ğŸ”„ ìƒˆ ìƒë‹´ ì‹œì‘"):
    st.session_state.clear()
    st.rerun()

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "info" not in st.session_state:
    st.session_state.info = {}
if "initialized" not in st.session_state:
    st.session_state.initialized = False
if "latest_strategy" not in st.session_state:
    st.session_state.latest_strategy = {}
if "phase_tool_summaries" not in st.session_state:
    st.session_state.phase_tool_summaries = {}
if "followup_ui" not in st.session_state:
    st.session_state.followup_ui = {}
if "followup_ui_key" not in st.session_state:
    st.session_state.followup_ui_key = 0
if "auto_followup_question" not in st.session_state:
    st.session_state.auto_followup_question = None
if "shown_followup_suggestion" not in st.session_state:
    st.session_state.shown_followup_suggestion = False
if "pending_question" not in st.session_state:
    st.session_state.pending_question = None
if "use_pending_question" not in st.session_state:
    st.session_state.use_pending_question = False
if "pending_question_button_key" not in st.session_state:
    st.session_state.pending_question_button_key = 0
if "is_generating" not in st.session_state:
    st.session_state.is_generating = False
if "copy_request" not in st.session_state:
    st.session_state.copy_request = None
if "copy_generation_in_progress" not in st.session_state:
    st.session_state.copy_generation_in_progress = False
if "copy_draft" not in st.session_state:
    st.session_state.copy_draft = ""
if "copy_context" not in st.session_state:
    st.session_state.copy_context = {}
if "copy_prompt_examples" not in st.session_state:
    st.session_state.copy_prompt_examples = []
if "copy_prompt_tips" not in st.session_state:
    st.session_state.copy_prompt_tips = []
if "copy_prompts_raw" not in st.session_state:
    st.session_state.copy_prompts_raw = ""
if "visual_request" not in st.session_state:
    st.session_state.visual_request = None
if "visual_generation_in_progress" not in st.session_state:
    st.session_state.visual_generation_in_progress = False
if "visual_brief" not in st.session_state:
    st.session_state.visual_brief = ""
if "visual_context" not in st.session_state:
    st.session_state.visual_context = {}
if "visual_prompt_examples" not in st.session_state:
    st.session_state.visual_prompt_examples = []
if "visual_prompt_tips" not in st.session_state:
    st.session_state.visual_prompt_tips = []
if "visual_prompts_raw" not in st.session_state:
    st.session_state.visual_prompts_raw = ""

if not st.session_state.initialized:
    with st.chat_message("assistant"):
        st.markdown(
            "ì•ˆë…•í•˜ì„¸ìš” ğŸ‘‹ ì €ëŠ” **AI ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸**ì…ë‹ˆë‹¤.\n\n"
            "ìƒì ëª…ì„ ì…ë ¥í•´ì£¼ì‹œë©´ ì—…ì¢…ê³¼ í”„ëœì°¨ì´ì¦ˆ ì—¬ë¶€ë¥¼ ë¶„ì„í•˜ê³ , "
            "ëª‡ ê°€ì§€ ì§ˆë¬¸ì„ í†µí•´ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆë“œë¦´ê²Œìš”.\n\n"
            "ì˜ˆ: `êµì´Œì¹˜í‚¨`, `íŒŒë¦¬ë°”ê²Œëœ¨`, `ì¹´í˜í–‰ë‹¹ì `, `ì™•ì‹­ë¦¬ë¼ì§€êµ­ë°¥`"
        )
    st.session_state.initialized = True

for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        if msg.get("type") == "strategy":
            message_container = st.container()
            render_strategy_payload(msg.get("data", {}), message_container, prefix=msg.get("id", "history"))
        else:
            st.markdown(msg["content"])

pending_question = st.session_state.get("pending_question")
missing_info = get_missing_info_fields(st.session_state.info)
if pending_question and missing_info:
    with st.container():
        st.info(
            "ì¡°ê¸ˆë§Œ ë” ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤ ì „ëµì„ ë” ì •í™•íˆ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”. "
            "ì§€ê¸ˆ ì •ë³´ë§Œìœ¼ë¡œë„ ë°”ë¡œ ë‹µë³€ì„ ë°›ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        )
        if st.button(
            "ì´ëŒ€ë¡œ ì§ˆë¬¸",
            key=f"use_question_{st.session_state.pending_question_button_key}",
            use_container_width=True,
            disabled=st.session_state.get("is_generating", False),
        ):
            st.session_state.use_pending_question = True
            st.session_state.auto_followup_question = pending_question
            st.session_state.pending_question_button_key += 1
            st.rerun()

latest_strategy_state = st.session_state.get("latest_strategy", {})
strategy_payload_for_assets = latest_strategy_state.get("payload")
raw_strategy_for_assets = latest_strategy_state.get("raw")
info_state_for_assets = st.session_state.get("info", {})

if not missing_info and (strategy_payload_for_assets or raw_strategy_for_assets):
    with st.container():
        render_asset_workshop(strategy_payload_for_assets, raw_strategy_for_assets, info_state_for_assets)

auto_followup_question = st.session_state.pop("auto_followup_question", None)
chat_box_value = st.chat_input("ìƒì ëª…ì„ ì…ë ¥í•˜ê±°ë‚˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”...")
user_input = auto_followup_question or chat_box_value

def add_message(role, content=None, **kwargs):
    message = {"role": role}
    if kwargs.get("type") == "strategy":
        message["type"] = "strategy"
        message["data"] = kwargs.get("data", {})
        message["id"] = kwargs.get("id", str(uuid.uuid4()))
        message["raw"] = kwargs.get("raw")
    else:
        message["content"] = content if content is not None else ""
    st.session_state.chat_history.append(message)


def answer_question_with_current_info(question_text: str):
    """ìˆ˜ì§‘ëœ ì •ë³´ë§Œìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€."""
    info = st.session_state.get("info", {})
    missing_fields = get_missing_info_fields(info)
    prompt = build_direct_question_prompt(info, question_text, missing_fields)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        st.session_state.is_generating = True
        try:
            answer = stream_gemini(
                prompt,
                output_placeholder=placeholder,
                status_text="ì§ˆë¬¸ì— ëŒ€í•œ ì¡°ì–¸ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ’¡",
                progress_text="ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ì¡°ì–¸ì„ ëª¨ìœ¼ê³  ìˆìŠµë‹ˆë‹¤... ğŸ§­",
                success_text="âœ… ë‹µë³€ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                error_status_text="ğŸš¨ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            )
        finally:
            st.session_state.is_generating = False
        if answer:
            guidance_text, suggested_question = parse_direct_answer(answer, info, question_text)
            guidance_text = guidance_text or answer.strip()
            ui_key = st.session_state.get("followup_ui_key", 0) + 1
            st.session_state.followup_ui_key = ui_key
            st.session_state.shown_followup_suggestion = False
            st.session_state.followup_ui = {
                "guidance": guidance_text,
                "evidence": [],
                "suggested_question": suggested_question,
                "key": ui_key,
            }

            placeholder.empty()
            with st.container():
                render_followup_panel(guidance_text, [], suggested_question, ui_key)

            log_message = "### ğŸ“˜ ìƒì„¸ ê°€ì´ë“œ\n\n" + guidance_text
            if suggested_question:
                log_message += f"\n\n**ê°€ëŠ¥í•œ ë‹¤ìŒ ì§ˆë¬¸:** {suggested_question}"
            add_message("assistant", log_message)

            st.session_state.latest_strategy = {
                "payload": None,
                "raw": guidance_text,
            }
        else:
            warning_text = "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ í•´ë³´ì‹œë©´ ë„ì›€ì´ ë  ìˆ˜ ìˆì–´ìš”."
            placeholder.warning(warning_text)
            add_message("assistant", warning_text)
            st.session_state.latest_strategy = {
                "payload": None,
                "raw": "",
            }

    if get_missing_info_fields(info):
        st.session_state.pending_question = question_text
    else:
        st.session_state.pending_question = None
    st.session_state.use_pending_question = False
    st.session_state.shown_followup_suggestion = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. ëŒ€í™” ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if user_input:
    use_pending = st.session_state.pop("use_pending_question", False)
    st.session_state.followup_ui = {}
    add_message("user", user_input)

    if use_pending:
        answer_question_with_current_info(user_input)
        st.stop()

    # â‘  ìƒì ëª…
    if "ìƒì ëª…" not in st.session_state.info:
        info_updates, detected_question = extract_initial_store_info(user_input)
        name = info_updates.get("ìƒì ëª…") or user_input.strip()
        st.session_state.info["ìƒì ëª…"] = name
        st.session_state.info["ì—…ì¢…"] = classify_hpsn_mct(name)
        st.session_state.info["í”„ëœì°¨ì´ì¦ˆì—¬ë¶€"] = "í”„ëœì°¨ì´ì¦ˆ" if is_franchise(name) else "ê°œì¸ì í¬"

        for field in ("ì í¬ì—°ë ¹", "ê³ ê°ì—°ë ¹ëŒ€", "ê³ ê°í–‰ë™"):
            if info_updates.get(field):
                st.session_state.info[field] = info_updates[field]

        st.session_state.pending_question = detected_question or user_input
        st.session_state.shown_followup_suggestion = False

        missing_fields = get_missing_info_fields(st.session_state.info)
        if missing_fields:
            next_field = missing_fields[0]
            if next_field == "ì í¬ì—°ë ¹":
                prompt_text = (
                    f"'{name}'ì€(ëŠ”) **{st.session_state.info['ì—…ì¢…']} ì—…ì¢…**ì´ë©° "
                    f"**{st.session_state.info['í”„ëœì°¨ì´ì¦ˆì—¬ë¶€']}**ë¡œ ì¶”ì •ë©ë‹ˆë‹¤. ğŸª\n\n"
                    "ê°œì—… ì‹œê¸°ê°€ ì–¸ì œì¸ê°€ìš”? (ì˜ˆ: 6ê°œì›” ì „, 2ë…„ ì „)"
                )
            elif next_field == "ê³ ê°ì—°ë ¹ëŒ€":
                prompt_text = "ì¢‹ì•„ìš” ğŸ‘ ì£¼ìš” ê³ ê°ì¸µì€ ì–´ë–¤ ì—°ë ¹ëŒ€ì¸ê°€ìš”? (20ëŒ€ / 30~40ëŒ€ / 50ëŒ€ ì´ìƒ)"
            else:
                prompt_text = "ë§ˆì§€ë§‰ìœ¼ë¡œ, ê³ ê° ìœ í˜•ì€ ì–´ë–¤ í¸ì¸ê°€ìš”? (ì‰¼í‘œë¡œ êµ¬ë¶„ ê°€ëŠ¥: ì¬ë°©ë¬¸, ì‹ ê·œ, ì§ì¥ì¸, ìœ ë™, ê±°ì£¼)"

            add_message("assistant", prompt_text + BUTTON_HINT)
            st.rerun()
        else:
            st.session_state.pending_question_button_key += 1
            st.session_state.pending_question = st.session_state.pending_question or user_input
            st.session_state.auto_followup_question = st.session_state.pending_question
            st.session_state.use_pending_question = True
            st.rerun()

    # â‘¡ ê°œì—… ì‹œê¸°
    elif "ì í¬ì—°ë ¹" not in st.session_state.info:
        months = re.findall(r"\d+", user_input)
        months = int(months[0]) if months else 0
        if months <= 12:
            st.session_state.info["ì í¬ì—°ë ¹"] = "ì‹ ê·œ"
        elif months <= 24:
            st.session_state.info["ì í¬ì—°ë ¹"] = "ì „í™˜ê¸°"
        else:
            st.session_state.info["ì í¬ì—°ë ¹"] = "ì˜¤ë˜ëœ"

        add_message("assistant", "ì¢‹ì•„ìš” ğŸ‘ ì£¼ìš” ê³ ê°ì¸µì€ ì–´ë–¤ ì—°ë ¹ëŒ€ì¸ê°€ìš”? (20ëŒ€ / 30~40ëŒ€ / 50ëŒ€ ì´ìƒ)" + BUTTON_HINT)
        st.rerun()

    # â‘¢ ê³ ê° ì—°ë ¹ëŒ€
    elif "ê³ ê°ì—°ë ¹ëŒ€" not in st.session_state.info:
        txt = user_input
        if "20" in txt:
            st.session_state.info["ê³ ê°ì—°ë ¹ëŒ€"] = "20ëŒ€ ì´í•˜ ê³ ê° ì¤‘ì‹¬"
        elif "30" in txt or "40" in txt:
            st.session_state.info["ê³ ê°ì—°ë ¹ëŒ€"] = "30~40ëŒ€ ê³ ê° ì¤‘ì‹¬"
        else:
            st.session_state.info["ê³ ê°ì—°ë ¹ëŒ€"] = "50ëŒ€ ì´ìƒ ê³ ê° ì¤‘ì‹¬"

        add_message("assistant", "ë§ˆì§€ë§‰ìœ¼ë¡œ, ê³ ê° ìœ í˜•ì€ ì–´ë–¤ í¸ì¸ê°€ìš”? (ì‰¼í‘œë¡œ êµ¬ë¶„ ê°€ëŠ¥: ì¬ë°©ë¬¸, ì‹ ê·œ, ì§ì¥ì¸, ìœ ë™, ê±°ì£¼)" + BUTTON_HINT)
        st.rerun()

    # â‘£ ê³ ê°í–‰ë™ (ë‹¤ì¤‘ ì…ë ¥ ìœ ì—° íŒŒì‹±)
    elif "ê³ ê°í–‰ë™" not in st.session_state.info:
        txt = user_input.lower()
        parts = re.split(r"[,/+\s]*(?:ë°|ì™€|ê·¸ë¦¬ê³ )?[,/+\s]*", txt)
        parts = [p for p in parts if p]

        behaviors = []
        for p in parts:
            if "ì¬" in p or "ë‹¨ê³¨" in p:
                behaviors.append("ì¬ë°©ë¬¸ ê³ ê°")
            if "ì‹ " in p or "ìƒˆ" in p:
                behaviors.append("ì‹ ê·œ ê³ ê°")
            if "ê±°ì£¼" in p or "ì£¼ë¯¼" in p:
                behaviors.append("ê±°ì£¼ ê³ ê°")
            if "ì§ì¥" in p or "ì˜¤í”¼ìŠ¤" in p or "íšŒì‚¬" in p:
                behaviors.append("ì§ì¥ì¸ ê³ ê°")
            if "ìœ ë™" in p or "ì§€ë‚˜" in p or "ê´€ê´‘" in p:
                behaviors.append("ìœ ë™ ê³ ê°")

        behaviors = list(set(behaviors)) or ["ì¼ë°˜ ê³ ê°"]
        st.session_state.info["ê³ ê°í–‰ë™"] = " + ".join(behaviors)

        # ... ê³ ê°í–‰ë™ê¹Œì§€ ìˆ˜ì§‘ëœ ë’¤:
        info = st.session_state.info
        persona = find_persona(
            info["ì—…ì¢…"], info["í”„ëœì°¨ì´ì¦ˆì—¬ë¶€"],
            info["ì í¬ì—°ë ¹"], info["ê³ ê°ì—°ë ¹ëŒ€"], info["ê³ ê°í–‰ë™"]
        )

        # â‘  persona prompt ë˜ëŠ” â‘¡ fallback prompt
        if persona and "prompt" in persona:
            prompt = ensure_data_evidence(persona["prompt"])
        else:
            prompt = ensure_data_evidence(
                "ë‹¤ìŒ ìƒì  ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3~5ë‹¨ê³„ Phaseë³„ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”.\n"
                "ê° PhaseëŠ” ëª©í‘œ, í•µì‹¬ ì•¡ì…˜(ì±„ë„Â·ì»¨í…ì¸ Â·ì˜¤í¼), ì˜ˆì‚°ë²”ìœ„, ì˜ˆìƒ KPI, ë‹¤ìŒ Phaseë¡œ ë„˜ì–´ê°€ëŠ” ê¸°ì¤€ì„ í¬í•¨í•˜ì„¸ìš”.\n\n"
                f"- ì—…ì¢…: {info['ì—…ì¢…']}\n"
                f"- í˜•íƒœ: {info['í”„ëœì°¨ì´ì¦ˆì—¬ë¶€']}\n"
                f"- ì í¬ì—°ë ¹: {info['ì í¬ì—°ë ¹']}\n"
                f"- ì£¼ìš” ê³ ê°ì—°ë ¹ëŒ€: {info['ê³ ê°ì—°ë ¹ëŒ€']}\n"
                f"- ê³ ê°í–‰ë™ íŠ¹ì„±: {info['ê³ ê°í–‰ë™']}\n"
                "ì‘ë‹µì€ ë¶ˆë¦¿ê³¼ í‘œë¥¼ ì ì ˆíˆ ì„ì–´ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."
            )

        #with st.expander("ğŸ“œ í”„ë¡¬í”„íŠ¸ ë³´ê¸°"):
        #    st.code(prompt, language="markdown")

        add_message("assistant", "ì´ì œ AI ìƒë‹´ì‚¬ê°€ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ìƒì„±í•©ë‹ˆë‹¤... â³")

        with st.chat_message("assistant"):
            st.markdown("### ğŸ“ˆ ìƒì„±ëœ ë§ˆì¼€íŒ… ì „ëµ ê²°ê³¼")
            content_placeholder = st.empty()
            st.session_state.is_generating = True
            try:
                result = stream_gemini(prompt, output_placeholder=content_placeholder)  # â¬…ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
            finally:
                st.session_state.is_generating = False
            if result:
                payload = parse_strategy_payload(result)
                if payload:
                    message_id = str(uuid.uuid4())
                    content_placeholder.empty()
                    strategy_container = st.container()
                    render_strategy_payload(payload, strategy_container, prefix=message_id)
                    st.session_state["latest_strategy"] = {
                        "payload": payload,
                        "raw": result,
                    }
                    st.session_state.shown_followup_suggestion = False
                    add_message(
                        "assistant",
                        type="strategy",
                        data=payload,
                        id=message_id,
                        raw=result,
                    )
                else:
                    summary_points = extract_executive_summary(result)
                    if summary_points:
                        summary_markdown = "#### âš¡ í•µì‹¬ ìš”ì•½\n\n" + "\n".join(
                            f"- {point}" for point in summary_points
                        )
                        content_placeholder.markdown(summary_markdown)
                        st.session_state["latest_strategy"] = {
                            "payload": None,
                            "raw": result,
                        }
                        st.session_state.shown_followup_suggestion = False
                        add_message("assistant", summary_markdown)
                    else:
                        fallback_notice = (
                            "êµ¬ì¡°í™”ëœ ì‘ë‹µì„ í‘œì‹œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”."
                        )
                        content_placeholder.warning(fallback_notice)
                        st.session_state["latest_strategy"] = {
                            "payload": None,
                            "raw": result,
                        }
                        st.session_state.shown_followup_suggestion = False
                        add_message("assistant", fallback_notice)
    else:
        latest_strategy_msg = get_latest_strategy_message()
        stored_strategy = st.session_state.get("latest_strategy", {})
        strategy_payload = None
        raw_strategy = ""

        if latest_strategy_msg:
            strategy_payload = latest_strategy_msg.get("data") or stored_strategy.get("payload")
            raw_strategy = latest_strategy_msg.get("raw") or stored_strategy.get("raw") or ""
        elif stored_strategy:
            strategy_payload = stored_strategy.get("payload")
            raw_strategy = stored_strategy.get("raw") or ""

        if not (strategy_payload or raw_strategy):
            pending_q = st.session_state.get("pending_question")
            info_state = st.session_state.get("info", {})
            if pending_q and info_state:
                answer_question_with_current_info(pending_q)
                st.rerun()

            fallback_notice = (
                "ì•„ì§ ì°¸ê³ í•  ì „ëµì´ ì—†ìŠµë‹ˆë‹¤. ìƒì  ì •ë³´ë¥¼ ì…ë ¥í•´ ë§ì¶¤ ì „ëµì„ ìƒì„±í•˜ê±°ë‚˜ "
                "ì§€ê¸ˆê¹Œì§€ì˜ ì •ë³´ë¡œ 'ì´ëŒ€ë¡œ ì§ˆë¬¸' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë°”ë¡œ ì¡°ì–¸ì„ ë°›ì•„ë³´ì„¸ìš”."
            )
            add_message("assistant", fallback_notice)
            st.rerun()

        followup_prompt = build_followup_prompt(
            user_input,
            st.session_state.get("info", {}),
            strategy_payload,
            raw_strategy,
        )

        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            st.session_state.is_generating = True
            try:
                followup_answer = stream_gemini(
                    followup_prompt,
                    output_placeholder=response_placeholder,
                    status_text="ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ’¡",
                    progress_text="ê¸°ì¡´ ì „ëµì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì´ë“œë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ§­",
                    success_text="âœ… ë‹µë³€ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    error_status_text="ğŸš¨ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                )
            finally:
                st.session_state.is_generating = False
            if followup_answer:
                parsed_followup = parse_followup_payload(followup_answer)
                if (
                    parsed_followup
                    and (
                        parsed_followup.get("summary_points")
                        or parsed_followup.get("detailed_guidance")
                    )
                ):
                    summary_points = (parsed_followup.get("summary_points") or [])[:2]
                    evidence_mentions = (parsed_followup.get("evidence_mentions") or [])[:3]
                    detail_text = parsed_followup.get("detailed_guidance", "")

                    guidance_parts = []
                    if summary_points:
                        guidance_parts.append("\n".join(point for point in summary_points))
                    if detail_text:
                        guidance_parts.append(detail_text)
                    guidance_text = "\n\n".join(part.strip() for part in guidance_parts if part.strip())
                    guidance_text = guidance_text or detail_text or followup_answer
                    suggested_question = (parsed_followup.get("suggested_question") or "").strip()
                    if not suggested_question:
                        suggested_question = default_suggested_question(
                            st.session_state.get("info", {}),
                            user_input,
                        )

                    ui_key = st.session_state.get("followup_ui_key", 0) + 1
                    st.session_state.followup_ui_key = ui_key
                    st.session_state.followup_ui = {
                        "guidance": guidance_text,
                        "evidence": evidence_mentions,
                        "suggested_question": suggested_question,
                        "key": ui_key,
                    }

                    log_sections = ["### ğŸ“˜ ìƒì„¸ ê°€ì´ë“œ", guidance_text]
                    if evidence_mentions:
                        log_sections.append("**ê·¼ê±°:**\n" + "\n".join(f"- {item}" for item in evidence_mentions))
                    log_message = "\n\n".join(section for section in log_sections if section.strip())
                    if log_message:
                        add_message("assistant", log_message)

                    response_placeholder.empty()
                    with st.container():
                        render_followup_panel(guidance_text, evidence_mentions, suggested_question, ui_key)
                else:
                    ui_key = st.session_state.get("followup_ui_key", 0) + 1
                    st.session_state.followup_ui_key = ui_key
                    fallback_suggestion = default_suggested_question(
                        st.session_state.get("info", {}),
                        user_input,
                    )
                    st.session_state.followup_ui = {
                        "guidance": followup_answer,
                        "evidence": [],
                        "suggested_question": fallback_suggestion,
                        "key": ui_key,
                    }

                    clean_answer = (followup_answer or "").strip()
                    if clean_answer:
                        log_message = "### ğŸ“˜ ìƒì„¸ ê°€ì´ë“œ\n\n" + clean_answer
                        if fallback_suggestion:
                            log_message += f"\n\n**ê°€ëŠ¥í•œ ë‹¤ìŒ ì§ˆë¬¸:** {fallback_suggestion}"
                        add_message("assistant", log_message)

                    response_placeholder.empty()
                    with st.container():
                        render_followup_panel(followup_answer, [], fallback_suggestion, ui_key)
            else:
                warning_text = "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ í•´ë³´ì‹œë©´ ë„ì›€ì´ ë  ìˆ˜ ìˆì–´ìš”."
                response_placeholder.warning(warning_text)
else:
    active_followup_ui = st.session_state.get("followup_ui", {})
    if active_followup_ui.get("guidance"):
        guidance_text = active_followup_ui.get("guidance", "")
        evidence_items = active_followup_ui.get("evidence", [])
        suggested_question = active_followup_ui.get("suggested_question", "")
        ui_key = active_followup_ui.get("key", st.session_state.get("followup_ui_key", 0))
        with st.chat_message("assistant"):
            render_followup_panel(guidance_text, evidence_items, suggested_question, ui_key)
